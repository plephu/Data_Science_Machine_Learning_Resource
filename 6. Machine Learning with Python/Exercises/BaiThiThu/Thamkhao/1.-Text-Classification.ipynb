{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0ad49cc0-f1a4-4be4-9b6c-736461e33367",
   "metadata": {},
   "source": [
    "# Text Classification with Naïve Bayes and NLP Techniques"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af957d3a-8e45-4057-bf8c-33e40205b96f",
   "metadata": {},
   "source": [
    "## 1. Prepare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a8d85675-aa3f-4e23-8dbb-d278582b5993",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1fe5b085-1129-49dc-ab1d-c63f9cfd4739",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>type</th>\n",
       "      <th>posts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>INFP</td>\n",
       "      <td>'One stereotype I disagree with is that INFPs ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>INTP</td>\n",
       "      <td>'The fridge and the buzzing of my roommates ph...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>INFP</td>\n",
       "      <td>'The thing is, the mbti is so much more than d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>INFP</td>\n",
       "      <td>'Almost never. The only other results I got ot...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ENFP</td>\n",
       "      <td>'She was curious of how many others didn't mat...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   type                                              posts\n",
       "0  INFP  'One stereotype I disagree with is that INFPs ...\n",
       "1  INTP  'The fridge and the buzzing of my roommates ph...\n",
       "2  INFP  'The thing is, the mbti is so much more than d...\n",
       "3  INFP  'Almost never. The only other results I got ot...\n",
       "4  ENFP  'She was curious of how many others didn't mat..."
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train = pd.read_csv(\"Text Classification/raw_train.csv\")\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2507d39a-9e46-442f-addc-eb682bda0066",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>posts</th>\n",
       "      <th>ID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5443</td>\n",
       "      <td>'Captain America: ISFJ Iron Man: ENTP Thor: ES...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4886</td>\n",
       "      <td>'Is a X-Files fan. (What else is there to say?...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7127</td>\n",
       "      <td>'Thank you!|||This exactly. I think my SO is a...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3206</td>\n",
       "      <td>'As stressful as school is, I'm happy to say t...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3528</td>\n",
       "      <td>Orthodox Iconoclast Yummy Donuts do you guys h...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                              posts  ID\n",
       "0        5443  'Captain America: ISFJ Iron Man: ENTP Thor: ES...   1\n",
       "1        4886  'Is a X-Files fan. (What else is there to say?...   2\n",
       "2        7127  'Thank you!|||This exactly. I think my SO is a...   3\n",
       "3        3206  'As stressful as school is, I'm happy to say t...   4\n",
       "4        3528  Orthodox Iconoclast Yummy Donuts do you guys h...   5"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test = pd.read_csv(\"Text Classification/raw_test.csv\")\n",
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a06145cf-a2cc-45c8-8f24-28b95696c0ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2169 entries, 0 to 2168\n",
      "Data columns (total 3 columns):\n",
      " #   Column      Non-Null Count  Dtype \n",
      "---  ------      --------------  ----- \n",
      " 0   Unnamed: 0  2169 non-null   int64 \n",
      " 1   posts       2169 non-null   object\n",
      " 2   ID          2169 non-null   int64 \n",
      "dtypes: int64(2), object(1)\n",
      "memory usage: 51.0+ KB\n"
     ]
    }
   ],
   "source": [
    "df_test.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dcc3f565-85cd-481e-ae16-0caaabd83fa8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 6506 entries, 0 to 6505\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   type    6506 non-null   object\n",
      " 1   posts   6506 non-null   object\n",
      "dtypes: object(2)\n",
      "memory usage: 101.8+ KB\n"
     ]
    }
   ],
   "source": [
    "df_train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "13e35020-3f72-445a-a0a8-b99e98880d87",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "INFP    1374\n",
       "INFJ    1078\n",
       "INTP    1023\n",
       "INTJ     811\n",
       "ENFP     510\n",
       "ENTP     499\n",
       "ISTP     265\n",
       "ISFP     210\n",
       "ENTJ     161\n",
       "ENFJ     154\n",
       "ISTJ     154\n",
       "ISFJ     119\n",
       "ESTP      61\n",
       "ESFP      32\n",
       "ESTJ      30\n",
       "ESFJ      25\n",
       "Name: type, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.type.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cd232fc-7817-40ac-ad28-ce9f4269a303",
   "metadata": {},
   "source": [
    "**NOTE: Imbalance dataset**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dbe4b01-f232-4bd8-9d64-7ab660a27834",
   "metadata": {},
   "source": [
    "## 2. Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7af7c8f3-54a6-4a32-bb9a-686a7bdc4112",
   "metadata": {},
   "source": [
    "### Modify dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "66e0c8c6-17fc-4fde-a1fd-232a7826a2f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test.drop('Unnamed: 0', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95fdc5f6-9ae2-477f-a0f6-4f24b7dd1a2a",
   "metadata": {},
   "source": [
    "### Check duplicated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bcfe9745-effd-492a-9f4c-2a83a9ce3355",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7f7e653f-16af-43c9-8e87-1155caa47043",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.duplicated().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6996c006-3e22-4276-87dd-70d3d69a0a66",
   "metadata": {},
   "source": [
    "### Clean text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f96f6a6e-50de-443d-9141-334bb099e0f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import regex\n",
    "import string\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer \n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.tokenize import sent_tokenize\n",
    "\n",
    "stop_words = stopwords.words('english')\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "stemmer = PorterStemmer()\n",
    "translator = str.maketrans('', '', string.punctuation + string.digits)\n",
    "\n",
    "def clean_process(text):\n",
    "    # Lowercasing\n",
    "    document = text.lower()\n",
    "    document = document.replace(\"’\",'')\n",
    "    document = regex.sub(r'\\.+', \".\", document)\n",
    "    \n",
    "    new_sentence = ''\n",
    "    for sentence in sent_tokenize(document):\n",
    "        pattern = r'(?i)\\b[a-z]+\\b'\n",
    "        sentence = ' '.join(regex.findall(pattern,sentence))\n",
    "        sentence = regex.sub(r'http\\S+', '', sentence)\n",
    "        sentence = regex.sub(r'[A-Za-z0-9]*@[A-Za-z]*\\.?[A-Za-z0-9]*', '', sentence)\n",
    "\n",
    "        # Tokenization\n",
    "        tokens = word_tokenize(sentence)\n",
    "    \n",
    "        # Stopword Removal\n",
    "        filtered_tokens = [token for token in tokens if token not in stop_words]\n",
    "\n",
    "        # Stemming\n",
    "        stemmed_tokens = [stemmer.stem(token) for token in filtered_tokens]\n",
    "\n",
    "        # Special Character and Number Removal\n",
    "        cleaned_tokens = [token.translate(translator) for token in stemmed_tokens]\n",
    "        \n",
    "        ## Lemmatization\n",
    "        lemmatized_tokens = [lemmatizer.lemmatize(token) for token in cleaned_tokens]\n",
    "\n",
    "        ## join to make a sentence\n",
    "        sentence = ' '.join(lemmatized_tokens)\n",
    "\n",
    "        ## append\n",
    "        new_sentence = new_sentence + sentence + '. ' \n",
    "        \n",
    "    document = new_sentence\n",
    "    document = regex.sub(r'\\s+', ' ', document).strip()\n",
    "    return document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2fa517a0-76ee-4f16-9a9c-ec0eff0c357a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'post one stereotyp disagre infp one giant caus. caus sever smaller caus. actual felt one time might someth wrong inspir diaphinisedbat first imag chiaroscuro http static flickr com jpg grownup http img xkcd com comic grownup png myspac http img xkcd com comic png delici http img xkcd com comic delici png dream present tiniest snorfer. happi happi happi http static flickr com jpg http static flickr com jpg http file wordpress com steven klein jpg w h like weird intx make sen. kitten bodi variou food. infp yum pop tart. convinc. pet peev peopl think sinc park lot common drive law longer appli. cat. anim lover. tri love littl felin devil accident forget recharg cellphon key realli realli like lost. cri hour straight seri final. lost fuel imagin emot. help understand peopl even better. hurley page best sourc imho. lot list seem weak human race infp infj. use. reconsid type may ask think nf fall love easili. lot unrequit love throughout life. suck muchli. sigh aw man got bad babi. mother would never say someth like know appreci beauti song without analyz dear power demand enfj woman. thank advanc. sincer infp male stream conscious mode realli eccentr sure. rare let side show peopl know well. guess know. mayb talk mine quantifi human condit. think way. buy copi sheet music moonlight sonata. idea explain world world fill anoth simmer. yay u write rewrit lot charact sketch. someth realli amaz float around mental ionospher need flesh charact lot. set multipl time thing said must sung said magic lost. hope help. shrug http www youtub com watch v brow youtub found gem. happi love video infp male also highli symbol love love love also get far descript. come man throw purpl monkey someth everi fall asleep. glad peopl quot articl knew sparkl wonder someon would put natali merchant. time. anoth torus amo. direct quot torus song describ irrevers damag pain lot good stuff thread. like doubl stuf oreo. chocol cover doubl stuf oreo. nom nom nom want notic want notic notic think brain flip upsid part system also clown panda umbrella. . like clown panda. . umbrella suspect thing get messi. grape vinaigrett raspberri vinaigrett thing decid kind juic. limit fruit. soup accept well. soup milk base soup. fruit juic infp moodi lol j k j work first play later. p play first work later. better descript put make decis till last possibl moment p exampl go bookstor paaaaaaaaaaaaaaaaartyyyyyyyyyyyyyyyyyy. woooooooooooooooooooo. wait mayb cap. . basic singl forev. sigh coffe help think seem unhappi dwell feel much. mayb sen unhappi come look ideal want. feel unhappi like dew flower petal get close see true beauti. like thing lot hard find. anywher find think p two type think like esfp enfp possibl estp. think ever go know sure narrow least. thank nice. new. sound like someth say year ago work season job hotel mile friend famili. phone commun sole letter write live need advic. get lot final pester woman enough get go least actual normal person tri identifi area life caus anxieti set concret goal remedi anxieti. know exactli feel. ideal ah man want swim pool juic understand understand understand. play video game storylin. know love know. torus amo. wrong idea infp. enough heard. one favorit song infp song. silent year excus hi everyon. say hi new etc. tongu interest place think pull chair. ok start talk. interject wise occasion witti comment.'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = '''\n",
    "\tposts\n",
    "1\t'One stereotype I disagree with is that INFPs all have this one giant Cause. I don't have A Cause: I have several smaller causes. I've actual felt at one time that there might be something wrong...|||Inspired by DiaphinisedBat's first image, some chiaroscuro:  http://farm6.static.flickr.com/5131/5470706131_8fc2d0646f.jpg ...|||GROWNUPS http://imgs.xkcd.com/comics/grownups.png  MYSPACE http://imgs.xkcd.com/comics/join_myspace.png  DELICIOUS http://imgs.xkcd.com/comics/delicious.png  DREAMS|||I present: The Tiniest Snorfer! :happy: :happy: :happy:     http://farm6.static.flickr.com/5129/5304355986_78e4751dba.jpg   http://farm5.static.flickr.com/4027/5145776103_6296c27044_z.jpg|||http://point001percent.files.wordpress.com/2009/05/steven-klein-3.jpg?w=500&h=323      I like weird.|||INTx: That doesn't make any sense. That kitten has the body of various foods. INFP: Yum..pop tarts!!!|||I convinced myself too. :D|||Some pet peeves:  1. People who think that since they're in a parking lot, common driving laws no longer apply.  2. Cats. I'm an animal lover. I try to love the little feline devils, but they're...|||...when you accidentally forget to recharge your cellphone.|||Where's my keys?|||I really really liked LOST. I cried for 2 hours straight during the series finale. LOST fueled my imagination and my emotions. It helped me understand other people even better.  And Hurley was...|||That page isn't the the best source, imho. A lot of that list seems weaknesses of the human race, not just INFPs and INFJs. I wouldn't use it myself. Why are you reconsidering your type, if I may ask?|||I think NFs fall in love easily. Lots of unrequited love throughout life. Sucks muchly. :sigh:|||Aw, man, you've got it bad, baby! :D My mother is a T, but she would never say something like that, and I know she can appreciate the beauty of a song without having to analyze it.|||Dear Powers That Be,  I demand more ENFJ women. Thank you in advance.  Sincerely, INFP male|||When I'm in stream of consciousness mode, I can be really eccentric, that's for sure. But I rarely let that side show to people I don't know well. So I guess I don't know why. Maybe because I talk...|||20210  here's mine.|||But you can't quantify the human condition. Think of it this way... You buy a copy of the sheet music for Moonlight Sonata. You have an idea to explain it to the world, so that the world is filled...|||Another Simmer! yays for us!|||I write (and rewrite) a lot of character sketches. I've something really amazing floating around in my mental ionosphere, but I need to flesh the characters out a lot. It's set in multiple time...|||There are some things that cannot be said, they must be sung, because if said the magic is lost.  I hope this helps some. :shrug:|||http://www.youtube.com/watch?v=5AhU12zC8fc  Just browsing YouTube and found this gem. :happy:  Love the video too, INFP male that I am, also highly symbolic, love it, love it, love it.|||I also couldn't get very far into the description. Come on, man, throw in a purple monkey or something every once in while so I don't fall asleep! I'm just glad people quoted the article so I knew...|||@ sparkle: wondering when someone would put some Natalie Merchant! About time!   Here's another Tori Amos. A direct quote from Tori herself: This song describes the irreversible damage and pain...|||Lot's of good stuff in this thread! Like double-stuffed oreos! Chocolate-covered double-stuffed oreos! :nom nom nom:|||...when you want to be noticed, but don't want to notice that you're being noticed.|||I think my brain just flipped upside down.|||I'm not a part of your system!|||And also there should be clowns and pandas with umbrellas. Why? Because I like clowns and pandas. That's why. (The umbrellas are there only because I suspect things will get messy.)|||Not grape vinaigrette: raspberry vinaigrette.|||The only thing is that I can't decide what kind of juice. And am I limited to fruit? And if not, wouldn't soup be acceptable as well? And if soup, why not milk-based soups. Then again, fruit juice is...|||INFPs, they're too moody, lol, j/k.|||J is work first, play later. P is play first, work later. A better description: if you put off making decisions till the last possible moment, you're a P.   For example, you go to the bookstore to...|||Paaaaaaaaaaaaaaaaartyyyyyyyyyyyyyyyyyy!!!!!!!!!!!!!!! Woooooooooooooooooooo!  (wait...maybe that should be in all caps?)|||I'm a 2w1, 7w6, 9w1. So basically I'll be single forever. :sigh: Coffee helps.|||I think we just seem unhappy because we dwell on our feelings so much. Maybe the sense of unhappiness comes from looking at ourselves and not being the ideal we want for ourselves? Feeling unhappy...|||We're like dew on flower petals: we're there, but you have to get close to see our true beauty.  We like doing things by ourselves a lot, so we can be hard to find. We'll be anywhere we can find...|||I think he's a P. The two types that I think are most like him are ESFP and ENFP, and possibly ESTP. I don't think I'm ever going to know for sure, but I'm narrowing it down, at least.   Thanks for...|||Nice.   I'm new here too. :)|||That sounds like something he'd say.|||About 15 years ago, I worked at a seasonal job at a hotel about 200 miles from all my friends and family. I had no phone (so communication was solely through letter writing), and I lived where the...|||I need some advice...  I get this a lot when I finally pester a woman enough to get her to go out with me at least once: You're actually a normal person.|||Try to identify what areas of your life are causing you the most anxiety and then set concrete goals to remedy that anxiety. I know exactly what you're feeling, and this is what I do. Having an ideal...|||Ah, man, now I want to swim in a pool of juice!|||...when you don't understand why you don't understand why you don't understand.  ...when you play video games for the storyline. (me)  ...when you don't know what love is but you do know what is...|||What! no Tori Amos?! Or do I have the wrong idea of INFP? Or not enough have heard of her? Here's one of my favorite songs of hers (a very INFP song, too).    Silent All These Years  Excuse...|||Hi, everyone. Just saying hi, new here, etc. :tongue: Interesting place you have here, think I'll pull up a chair. Ok, start talking. I'll just interject a wise and occasionally witty comment...'\n",
    "'''\n",
    "clean_process(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "71036742-7b19-4245-ae68-fe6883e992d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['cleaned'] = df_train.posts.apply(lambda x: clean_process(x))\n",
    "df_test['cleaned'] = df_test.posts.apply(lambda x: clean_process(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1958dda-8899-45aa-8568-299a37984a73",
   "metadata": {},
   "source": [
    "## 3. Train test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "da4572bc-fd4e-4c4e-b54c-23d30aad9ba6",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = df_train['cleaned']\n",
    "y_train = df_train['type']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c686e65f-5b3a-4648-84f7-24cf91b8aa65",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = df_test['cleaned']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "70bbbe38-5c08-4086-b31c-a01ba6b4134c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6506,)\n",
      "(2169,)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fce2788-a6d6-49c1-afcf-9b37e7ba1a8e",
   "metadata": {},
   "source": [
    "## 4. Data Transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0658340b-f128-4934-acc8-62a0afbe6fd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e6f2a60f-db5f-4dbe-81b5-0c67c27e452a",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b8796661-3023-44de-ab1d-3fbe4c8aa1c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_T = vectorizer.fit_transform(X_train).toarray()\n",
    "X_test_T = vectorizer.transform(X_test).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "82873645-416d-4836-bc54-06122b664911",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_T[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "69cdf117-ebb1-4198-a0c3-3456c98645cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_T[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d2f1cfe-6868-4f1d-a0ee-849676fe39a0",
   "metadata": {},
   "source": [
    "## 5. Build Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a72f39c4-433e-4da5-97e8-cc45b961f9a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3e72f7c2-2900-41fc-a81b-8f332aa42bf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MultinomialNB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "33b5a635-65d2-4ffb-84e0-9ebe8c2a02af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6847525361205041"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Training phase\n",
    "model.fit(X_train_T, y_train)\n",
    "model.score(X_train_T, y_train) # accuracy of model on the training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5939b7a2-2a9f-438d-b8ec-f9e3a533488e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['INFJ', 'INTJ', 'INFP', ..., 'INFP', 'INFP', 'INFP'], dtype='<U4')"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Testing phase\n",
    "preds = model.predict(X_test_T)\n",
    "preds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f03ade4-7de9-4a51-814d-f0546c9e7974",
   "metadata": {},
   "source": [
    "## 6. Evaluate Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8155b392-6b92-448b-a389-3cc0faf5afce",
   "metadata": {},
   "source": [
    "### Load label ground truth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "00a9ffc1-4ecf-42ad-a6ed-095fb7cd014f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>INFJ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>INTJ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>ENTJ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>ISFP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>ENTP</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id Category\n",
       "0   1     INFJ\n",
       "1   2     INTJ\n",
       "2   3     ENTJ\n",
       "3   4     ISFP\n",
       "4   5     ENTP"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_solution = pd.read_csv(\"Text Classification/solution.csv\")\n",
    "df_solution.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f9d8214a-c60e-431b-ae8d-13537dd5b095",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       INFJ\n",
       "1       INTJ\n",
       "2       ENTJ\n",
       "3       ISFP\n",
       "4       ENTP\n",
       "        ... \n",
       "2164    INFJ\n",
       "2165    INTJ\n",
       "2166    INFJ\n",
       "2167    ENFP\n",
       "2168    INFP\n",
       "Name: Category, Length: 2169, dtype: object"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test2 = df_test.copy()\n",
    "df_test2.rename({\"ID\":\"Id\"}, axis=\"columns\", inplace=True)\n",
    "df_test2 = pd.merge(df_test2, df_solution, on=\"Id\")\n",
    "y_test = df_test2['Category']\n",
    "y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24cec07d-055f-44ad-b72b-12a7ec04212d",
   "metadata": {},
   "source": [
    "### Evaluate Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e391d9e4-3881-4d7b-9492-a8bf87a09ec0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "216b95f8-bf3b-4049-b968-cce2f29ab8b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "        ENFJ     0.0000    0.0000    0.0000         0\n",
      "        ENFP     0.0545    0.5000    0.0984        18\n",
      "        ENTJ     0.0000    0.0000    0.0000         0\n",
      "        ENTP     0.0484    0.4737    0.0878        19\n",
      "        ESFJ     0.0000    0.0000    0.0000         0\n",
      "        ESFP     0.0000    0.0000    0.0000         0\n",
      "        ESTJ     0.0000    0.0000    0.0000         0\n",
      "        ESTP     0.0000    0.0000    0.0000         0\n",
      "        INFJ     0.5689    0.4313    0.4906       517\n",
      "        INFP     0.8253    0.3743    0.5150      1010\n",
      "        INTJ     0.3107    0.6259    0.4153       139\n",
      "        INTP     0.6548    0.3966    0.4940       464\n",
      "        ISFJ     0.0000    0.0000    0.0000         0\n",
      "        ISFP     0.0000    0.0000    0.0000         1\n",
      "        ISTJ     0.0000    0.0000    0.0000         0\n",
      "        ISTP     0.0139    1.0000    0.0274         1\n",
      "\n",
      "    accuracy                         0.4108      2169\n",
      "   macro avg     0.1548    0.2376    0.1330      2169\n",
      "weighted avg     0.6808    0.4108    0.4906      2169\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(preds, y_test, digits=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70fbc062-d784-4648-b904-0bafa6346bc6",
   "metadata": {},
   "source": [
    "**NOTE: Train accuracy: 68.47%, Test accuracy: 41.08%**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ebd4b01-4c5e-4fd1-b3cb-a907ba384995",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
