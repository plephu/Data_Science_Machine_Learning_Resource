{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CFATBjJbr0ua"
   },
   "source": [
    "# Chapter 7: Demo pre NLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 10378,
     "status": "ok",
     "timestamp": 1668673449429,
     "user": {
      "displayName": "Phuong Khuat Thuy",
      "userId": "16807426118474640783"
     },
     "user_tz": -420
    },
    "id": "ZcMYPfYXr40h",
    "outputId": "f7ff2899-b18c-4167-dae3-8b2e2f5a8b49"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: underthesea in c:\\program files\\python39\\lib\\site-packages (6.2.0)\n",
      "Requirement already satisfied: nltk in c:\\program files\\python39\\lib\\site-packages (from underthesea) (3.8.1)\n",
      "Requirement already satisfied: scikit-learn in c:\\program files\\python39\\lib\\site-packages (from underthesea) (1.2.0)\n",
      "Requirement already satisfied: underthesea-core==1.0.0 in c:\\program files\\python39\\lib\\site-packages (from underthesea) (1.0.0)\n",
      "Requirement already satisfied: python-crfsuite>=0.9.6 in c:\\program files\\python39\\lib\\site-packages (from underthesea) (0.9.8)\n",
      "Requirement already satisfied: joblib in c:\\program files\\python39\\lib\\site-packages (from underthesea) (1.2.0)\n",
      "Requirement already satisfied: PyYAML in c:\\program files\\python39\\lib\\site-packages (from underthesea) (6.0)\n",
      "Requirement already satisfied: requests in c:\\program files\\python39\\lib\\site-packages (from underthesea) (2.28.1)\n",
      "Requirement already satisfied: tqdm in c:\\program files\\python39\\lib\\site-packages (from underthesea) (4.64.1)\n",
      "Requirement already satisfied: Click>=6.0 in c:\\program files\\python39\\lib\\site-packages (from underthesea) (8.1.3)\n",
      "Requirement already satisfied: colorama in c:\\program files\\python39\\lib\\site-packages (from Click>=6.0->underthesea) (0.4.6)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\program files\\python39\\lib\\site-packages (from nltk->underthesea) (2021.11.10)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\program files\\python39\\lib\\site-packages (from requests->underthesea) (3.4)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in c:\\program files\\python39\\lib\\site-packages (from requests->underthesea) (2.1.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\program files\\python39\\lib\\site-packages (from requests->underthesea) (2022.9.24)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\program files\\python39\\lib\\site-packages (from requests->underthesea) (1.26.12)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\program files\\python39\\lib\\site-packages (from scikit-learn->underthesea) (3.1.0)\n",
      "Requirement already satisfied: scipy>=1.3.2 in c:\\program files\\python39\\lib\\site-packages (from scikit-learn->underthesea) (1.9.3)\n",
      "Requirement already satisfied: numpy>=1.17.3 in c:\\users\\phamp\\appdata\\roaming\\python\\python39\\site-packages (from scikit-learn->underthesea) (1.23.4)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip available: 22.3.1 -> 23.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install underthesea"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "K2BkS8AQryDY"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from underthesea import word_tokenize, pos_tag, sent_tokenize\n",
    "import regex\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "-w6OeQ4AryDb"
   },
   "outputs": [],
   "source": [
    "# https://underthesea.readthedocs.io/en/v1.1.5/readme.html\n",
    "# https://github.com/undertheseanlp/underthesea"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EnHQRMxCryDc"
   },
   "outputs": [],
   "source": [
    "##LOAD EMOJICON\n",
    "file = open('files/emojicon.txt', 'r', encoding=\"utf8\")\n",
    "emoji_lst = file.read().split('\\n')\n",
    "emoji_dict = {}\n",
    "for line in emoji_lst:\n",
    "    key, value = line.split('\\t')\n",
    "    emoji_dict[key] = str(value)\n",
    "file.close()\n",
    "#################\n",
    "#LOAD TEENCODE\n",
    "file = open('files/teencode.txt', 'r', encoding=\"utf8\")\n",
    "teen_lst = file.read().split('\\n')\n",
    "teen_dict = {}\n",
    "for line in teen_lst:\n",
    "    key, value = line.split('\\t')\n",
    "    teen_dict[key] = str(value)\n",
    "file.close()\n",
    "###############\n",
    "#LOAD TRANSLATE ENGLISH -> VNMESE\n",
    "file = open('files/english-vnmese.txt', 'r', encoding=\"utf8\")\n",
    "english_lst = file.read().split('\\n')\n",
    "english_dict = {}\n",
    "for line in english_lst:\n",
    "    key, value = line.split('\\t')\n",
    "    english_dict[key] = str(value)\n",
    "file.close()\n",
    "################\n",
    "#LOAD wrong words\n",
    "file = open('files/wrong-word.txt', 'r', encoding=\"utf8\")\n",
    "wrong_lst = file.read().split('\\n')\n",
    "file.close()\n",
    "#################\n",
    "#LOAD STOPWORDS\n",
    "file = open('files/vietnamese-stopwords.txt', 'r', encoding=\"utf8\")\n",
    "stopwords_lst = file.read().split('\\n')\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QBoO69oWryDc"
   },
   "outputs": [],
   "source": [
    "def process_text(text, emoji_dict, teen_dict, wrong_lst):\n",
    "    document = text.lower()\n",
    "    document = document.replace(\"â€™\",'')\n",
    "    document = regex.sub(r'\\.+', \".\", document)\n",
    "    new_sentence =''\n",
    "    for sentence in sent_tokenize(document):\n",
    "        # if not(sentence.isascii()):\n",
    "        ###### CONVERT EMOJICON\n",
    "        sentence = ''.join(emoji_dict[word]+' ' if word in emoji_dict else word for word in list(sentence))\n",
    "        ###### CONVERT TEENCODE\n",
    "        sentence = ' '.join(teen_dict[word] if word in teen_dict else word for word in sentence.split())\n",
    "        ###### DEL Punctuation & Numbers\n",
    "        pattern = r'(?i)\\b[a-zÃ¡Ã áº£Ã£áº¡Äƒáº¯áº±áº³áºµáº·Ã¢áº¥áº§áº©áº«áº­Ã©Ã¨áº»áº½áº¹Ãªáº¿á»á»ƒá»…á»‡Ã³Ã²á»Ãµá»Ã´á»‘á»“á»•á»—á»™Æ¡á»›á»á»Ÿá»¡á»£Ã­Ã¬á»‰Ä©á»‹ÃºÃ¹á»§Å©á»¥Æ°á»©á»«á»­á»¯á»±Ã½á»³á»·á»¹á»µÄ‘]+\\b'\n",
    "        sentence = ' '.join(regex.findall(pattern,sentence))\n",
    "        ###### DEL wrong words   \n",
    "        sentence = ' '.join('' if word in wrong_lst else word for word in sentence.split())\n",
    "        new_sentence = new_sentence+ sentence + '. '                    \n",
    "    document = new_sentence  \n",
    "    #print(document)\n",
    "    ###### DEL excess blank space\n",
    "    document = regex.sub(r'\\s+', ' ', document).strip()\n",
    "    return document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "k896J_YKryDd"
   },
   "outputs": [],
   "source": [
    "example = '''Äáº§u nÄƒm vk ck tÃ´i Ä‘i ctÃ¡c á»Ÿ sg Ã­t ngÃ y. \n",
    "ChÃºng tÃ´i á»Ÿ ks XXX. Ks á»•n ğŸ‘, ğŸ˜Š. \n",
    "Phá»¥c vá»¥ tá»‘t chÄƒm sÃ³c nhiá»‡t tÃ¬nh. \n",
    "Buffet ngon nhiá»u mÃ³n. PhÃ²ng sáº¡ch sáº½.Ä‘áº§y Ä‘á»§ tiá»‡n nghi, view Ä‘áº¹p hÆ°á»›ng ra sÃ´ng sg.  \n",
    "NhÃ¢n viÃªn thÃ¡i Ä‘á»™ phá»¥c vá»¥ tá»‘t ğŸ’™. Vá»‹ trÃ­ trung tÃ¢m tiá»‡n cho di chuyá»ƒn thÄƒm quan.'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0dTlk75JryDe"
   },
   "outputs": [],
   "source": [
    "document = process_text(example, emoji_dict, teen_dict, wrong_lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1MEKFTiKryDe"
   },
   "outputs": [],
   "source": [
    "# Chuáº©n hÃ³a unicode tiáº¿ng viá»‡t\n",
    "def loaddicchar():\n",
    "    uniChars = \"Ã Ã¡áº£Ã£áº¡Ã¢áº§áº¥áº©áº«áº­Äƒáº±áº¯áº³áºµáº·Ã¨Ã©áº»áº½áº¹Ãªá»áº¿á»ƒá»…á»‡Ä‘Ã¬Ã­á»‰Ä©á»‹Ã²Ã³á»Ãµá»Ã´á»“á»‘á»•á»—á»™Æ¡á»á»›á»Ÿá»¡á»£Ã¹Ãºá»§Å©á»¥Æ°á»«á»©á»­á»¯á»±á»³Ã½á»·á»¹á»µÃ€Ãáº¢Ãƒáº Ã‚áº¦áº¤áº¨áºªáº¬Ä‚áº°áº®áº²áº´áº¶ÃˆÃ‰áººáº¼áº¸ÃŠá»€áº¾á»‚á»„á»†ÄÃŒÃá»ˆÄ¨á»ŠÃ’Ã“á»Ã•á»ŒÃ”á»’á»á»”á»–á»˜Æ á»œá»šá»á» á»¢Ã™Ãšá»¦Å¨á»¤Æ¯á»ªá»¨á»¬á»®á»°á»²Ãá»¶á»¸á»´Ã‚Ä‚ÄÃ”Æ Æ¯\"\n",
    "    unsignChars = \"aaaaaaaaaaaaaaaaaeeeeeeeeeeediiiiiooooooooooooooooouuuuuuuuuuuyyyyyAAAAAAAAAAAAAAAAAEEEEEEEEEEEDIIIOOOOOOOOOOOOOOOOOOOUUUUUUUUUUUYYYYYAADOOU\"\n",
    "\n",
    "    dic = {}\n",
    "    char1252 = 'aÌ€|aÌ|aÌ‰|aÌƒ|aÌ£|Ã¢Ì€|Ã¢Ì|Ã¢Ì‰|Ã¢Ìƒ|Ã¢Ì£|ÄƒÌ€|ÄƒÌ|ÄƒÌ‰|ÄƒÌƒ|ÄƒÌ£|eÌ€|eÌ|eÌ‰|eÌƒ|eÌ£|ÃªÌ€|ÃªÌ|ÃªÌ‰|ÃªÌƒ|ÃªÌ£|iÌ€|iÌ|iÌ‰|iÌƒ|iÌ£|oÌ€|oÌ|oÌ‰|oÌƒ|oÌ£|Ã´Ì€|Ã´Ì|Ã´Ì‰|Ã´Ìƒ|Ã´Ì£|Æ¡Ì€|Æ¡Ì|Æ¡Ì‰|Æ¡Ìƒ|Æ¡Ì£|uÌ€|uÌ|uÌ‰|uÌƒ|uÌ£|Æ°Ì€|Æ°Ì|Æ°Ì‰|Æ°Ìƒ|Æ°Ì£|yÌ€|yÌ|yÌ‰|yÌƒ|yÌ£|AÌ€|AÌ|AÌ‰|AÌƒ|AÌ£|Ã‚Ì€|Ã‚Ì|Ã‚Ì‰|Ã‚Ìƒ|Ã‚Ì£|Ä‚Ì€|Ä‚Ì|Ä‚Ì‰|Ä‚Ìƒ|Ä‚Ì£|EÌ€|EÌ|EÌ‰|EÌƒ|EÌ£|ÃŠÌ€|ÃŠÌ|ÃŠÌ‰|ÃŠÌƒ|ÃŠÌ£|IÌ€|IÌ|IÌ‰|IÌƒ|IÌ£|OÌ€|OÌ|OÌ‰|OÌƒ|OÌ£|Ã”Ì€|Ã”Ì|Ã”Ì‰|Ã”Ìƒ|Ã”Ì£|Æ Ì€|Æ Ì|Æ Ì‰|Æ Ìƒ|Æ Ì£|UÌ€|UÌ|UÌ‰|UÌƒ|UÌ£|Æ¯Ì€|Æ¯Ì|Æ¯Ì‰|Æ¯Ìƒ|Æ¯Ì£|YÌ€|YÌ|YÌ‰|YÌƒ|YÌ£'.split(\n",
    "        '|')\n",
    "    charutf8 = \"Ã |Ã¡|áº£|Ã£|áº¡|áº§|áº¥|áº©|áº«|áº­|áº±|áº¯|áº³|áºµ|áº·|Ã¨|Ã©|áº»|áº½|áº¹|á»|áº¿|á»ƒ|á»…|á»‡|Ã¬|Ã­|á»‰|Ä©|á»‹|Ã²|Ã³|á»|Ãµ|á»|á»“|á»‘|á»•|á»—|á»™|á»|á»›|á»Ÿ|á»¡|á»£|Ã¹|Ãº|á»§|Å©|á»¥|á»«|á»©|á»­|á»¯|á»±|á»³|Ã½|á»·|á»¹|á»µ|Ã€|Ã|áº¢|Ãƒ|áº |áº¦|áº¤|áº¨|áºª|áº¬|áº°|áº®|áº²|áº´|áº¶|Ãˆ|Ã‰|áºº|áº¼|áº¸|á»€|áº¾|á»‚|á»„|á»†|ÃŒ|Ã|á»ˆ|Ä¨|á»Š|Ã’|Ã“|á»|Ã•|á»Œ|á»’|á»|á»”|á»–|á»˜|á»œ|á»š|á»|á» |á»¢|Ã™|Ãš|á»¦|Å¨|á»¤|á»ª|á»¨|á»¬|á»®|á»°|á»²|Ã|á»¶|á»¸|á»´\".split(\n",
    "        '|')\n",
    "    for i in range(len(char1252)):\n",
    "        dic[char1252[i]] = charutf8[i]\n",
    "    return dic\n",
    " \n",
    "# ÄÆ°a toÃ n bá»™ dá»¯ liá»‡u qua hÃ m nÃ y Ä‘á»ƒ chuáº©n hÃ³a láº¡i\n",
    "def covert_unicode(txt):\n",
    "    dicchar = loaddicchar()\n",
    "    return regex.sub(\n",
    "        r'aÌ€|aÌ|aÌ‰|aÌƒ|aÌ£|Ã¢Ì€|Ã¢Ì|Ã¢Ì‰|Ã¢Ìƒ|Ã¢Ì£|ÄƒÌ€|ÄƒÌ|ÄƒÌ‰|ÄƒÌƒ|ÄƒÌ£|eÌ€|eÌ|eÌ‰|eÌƒ|eÌ£|ÃªÌ€|ÃªÌ|ÃªÌ‰|ÃªÌƒ|ÃªÌ£|iÌ€|iÌ|iÌ‰|iÌƒ|iÌ£|oÌ€|oÌ|oÌ‰|oÌƒ|oÌ£|Ã´Ì€|Ã´Ì|Ã´Ì‰|Ã´Ìƒ|Ã´Ì£|Æ¡Ì€|Æ¡Ì|Æ¡Ì‰|Æ¡Ìƒ|Æ¡Ì£|uÌ€|uÌ|uÌ‰|uÌƒ|uÌ£|Æ°Ì€|Æ°Ì|Æ°Ì‰|Æ°Ìƒ|Æ°Ì£|yÌ€|yÌ|yÌ‰|yÌƒ|yÌ£|AÌ€|AÌ|AÌ‰|AÌƒ|AÌ£|Ã‚Ì€|Ã‚Ì|Ã‚Ì‰|Ã‚Ìƒ|Ã‚Ì£|Ä‚Ì€|Ä‚Ì|Ä‚Ì‰|Ä‚Ìƒ|Ä‚Ì£|EÌ€|EÌ|EÌ‰|EÌƒ|EÌ£|ÃŠÌ€|ÃŠÌ|ÃŠÌ‰|ÃŠÌƒ|ÃŠÌ£|IÌ€|IÌ|IÌ‰|IÌƒ|IÌ£|OÌ€|OÌ|OÌ‰|OÌƒ|OÌ£|Ã”Ì€|Ã”Ì|Ã”Ì‰|Ã”Ìƒ|Ã”Ì£|Æ Ì€|Æ Ì|Æ Ì‰|Æ Ìƒ|Æ Ì£|UÌ€|UÌ|UÌ‰|UÌƒ|UÌ£|Æ¯Ì€|Æ¯Ì|Æ¯Ì‰|Æ¯Ìƒ|Æ¯Ì£|YÌ€|YÌ|YÌ‰|YÌƒ|YÌ£',\n",
    "        lambda x: dicchar[x.group()], txt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IhM3oFS8ryDf"
   },
   "outputs": [],
   "source": [
    "document = covert_unicode(document)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nChQz0RiryDg"
   },
   "outputs": [],
   "source": [
    "def process_special_word(text):\n",
    "    new_text = ''\n",
    "    text_lst = text.split()\n",
    "    i= 0\n",
    "    if 'khÃ´ng' in text_lst:\n",
    "        while i <= len(text_lst) - 1:\n",
    "            word = text_lst[i]\n",
    "            #print(word)\n",
    "            #print(i)\n",
    "            if  word == 'khÃ´ng':\n",
    "                next_idx = i+1\n",
    "                if next_idx <= len(text_lst) -1:\n",
    "                    word = word +'_'+ text_lst[next_idx]\n",
    "                i= next_idx + 1\n",
    "            else:\n",
    "                i = i+1\n",
    "            new_text = new_text + word + ' '\n",
    "    else:\n",
    "        new_text = text\n",
    "    return new_text.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 53
    },
    "executionInfo": {
     "elapsed": 12,
     "status": "ok",
     "timestamp": 1668673673754,
     "user": {
      "displayName": "Phuong Khuat Thuy",
      "userId": "16807426118474640783"
     },
     "user_tz": -420
    },
    "id": "fOEspKNjryDg",
    "outputId": "6fd2d25c-ead3-4fc8-a30d-e62f8b456b0b"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'Ä‘áº§u nÄƒm vá»£ chá»“ng tÃ´i Ä‘i cÃ´ng tÃ¡c á»Ÿ sÃ i gÃ²n Ã­t ngÃ y. chÃºng tÃ´i á»Ÿ khÃ¡ch sáº¡n . khÃ¡ch sáº¡n á»•n thÃ­ch cÆ°á»i. phá»¥c vá»¥ tá»‘t chÄƒm sÃ³c nhiá»‡t tÃ¬nh. nhiá»u mÃ³n. phÃ²ng sáº¡ch sáº½ Ä‘áº§y Ä‘á»§ tiá»‡n Ä‘áº¹p hÆ°á»›ng sÃ´ng . nhÃ¢n viÃªn thÃ¡i Ä‘á»™ phá»¥c vá»¥ tá»‘t yÃªu. vá»‹ trÃ­ tÃ¢m tiá»‡n cho di chuyá»ƒn thÄƒm quan.'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = process_special_word(document)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cb4HTaNQryDh"
   },
   "outputs": [],
   "source": [
    "def process_postag_thesea(text):\n",
    "    new_document = ''\n",
    "    for sentence in sent_tokenize(text):\n",
    "        sentence = sentence.replace('.','')\n",
    "        ###### POS tag\n",
    "        lst_word_type = ['A','AB','V','VB','VY','R']\n",
    "        sentence = ' '.join( word[0] if word[1].upper() in lst_word_type else '' for word in pos_tag(process_special_word(word_tokenize(sentence, format=\"text\"))))\n",
    "        new_document = new_document + sentence + ' '\n",
    "    ###### DEL excess blank space\n",
    "    new_document = regex.sub(r'\\s+', ' ', new_document).strip()\n",
    "    return new_document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LY8ojbejryDh"
   },
   "outputs": [],
   "source": [
    "document = process_postag_thesea(document)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "executionInfo": {
     "elapsed": 11,
     "status": "ok",
     "timestamp": 1668673673755,
     "user": {
      "displayName": "Phuong Khuat Thuy",
      "userId": "16807426118474640783"
     },
     "user_tz": -420
    },
    "id": "fB8f-uuQryDi",
    "outputId": "07667177-5590-447b-f237-e866a165ea2c"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'Ä‘i cÃ´ng_tÃ¡c Ã­t á»•n thÃ­ch cÆ°á»i tá»‘t nhiá»u sáº¡ch_sáº½ tiá»‡n Ä‘áº¹p phá»¥c_vá»¥ tá»‘t yÃªu tiá»‡n di_chuyá»ƒn thÄƒm'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ip_xMlXgryDi"
   },
   "outputs": [],
   "source": [
    "def remove_stopword(text, stopwords):\n",
    "    ###### REMOVE stop words\n",
    "    document = ' '.join('' if word in stopwords else word for word in text.split())\n",
    "    #print(document)\n",
    "    ###### DEL excess blank space\n",
    "    document = regex.sub(r'\\s+', ' ', document).strip()\n",
    "    return document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "executionInfo": {
     "elapsed": 11,
     "status": "ok",
     "timestamp": 1668673673756,
     "user": {
      "displayName": "Phuong Khuat Thuy",
      "userId": "16807426118474640783"
     },
     "user_tz": -420
    },
    "id": "F3_0ruTYryDi",
    "outputId": "375b22d2-8ee2-42ed-f1ec-6151f50d34ae"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'cÃ´ng_tÃ¡c á»•n thÃ­ch cÆ°á»i tá»‘t sáº¡ch_sáº½ tiá»‡n Ä‘áº¹p phá»¥c_vá»¥ tá»‘t yÃªu tiá»‡n di_chuyá»ƒn thÄƒm'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "document = remove_stopword(document, stopwords_lst)\n",
    "document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UlZhA4_AryDj"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
