{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CFATBjJbr0ua"
   },
   "source": [
    "# Chapter 7: Demo pre NLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 10378,
     "status": "ok",
     "timestamp": 1668673449429,
     "user": {
      "displayName": "Phuong Khuat Thuy",
      "userId": "16807426118474640783"
     },
     "user_tz": -420
    },
    "id": "ZcMYPfYXr40h",
    "outputId": "f7ff2899-b18c-4167-dae3-8b2e2f5a8b49"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: underthesea in c:\\program files\\python39\\lib\\site-packages (6.2.0)\n",
      "Requirement already satisfied: nltk in c:\\program files\\python39\\lib\\site-packages (from underthesea) (3.8.1)\n",
      "Requirement already satisfied: scikit-learn in c:\\program files\\python39\\lib\\site-packages (from underthesea) (1.2.0)\n",
      "Requirement already satisfied: underthesea-core==1.0.0 in c:\\program files\\python39\\lib\\site-packages (from underthesea) (1.0.0)\n",
      "Requirement already satisfied: python-crfsuite>=0.9.6 in c:\\program files\\python39\\lib\\site-packages (from underthesea) (0.9.8)\n",
      "Requirement already satisfied: joblib in c:\\program files\\python39\\lib\\site-packages (from underthesea) (1.2.0)\n",
      "Requirement already satisfied: PyYAML in c:\\program files\\python39\\lib\\site-packages (from underthesea) (6.0)\n",
      "Requirement already satisfied: requests in c:\\program files\\python39\\lib\\site-packages (from underthesea) (2.28.1)\n",
      "Requirement already satisfied: tqdm in c:\\program files\\python39\\lib\\site-packages (from underthesea) (4.64.1)\n",
      "Requirement already satisfied: Click>=6.0 in c:\\program files\\python39\\lib\\site-packages (from underthesea) (8.1.3)\n",
      "Requirement already satisfied: colorama in c:\\program files\\python39\\lib\\site-packages (from Click>=6.0->underthesea) (0.4.6)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\program files\\python39\\lib\\site-packages (from nltk->underthesea) (2021.11.10)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\program files\\python39\\lib\\site-packages (from requests->underthesea) (3.4)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in c:\\program files\\python39\\lib\\site-packages (from requests->underthesea) (2.1.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\program files\\python39\\lib\\site-packages (from requests->underthesea) (2022.9.24)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\program files\\python39\\lib\\site-packages (from requests->underthesea) (1.26.12)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\program files\\python39\\lib\\site-packages (from scikit-learn->underthesea) (3.1.0)\n",
      "Requirement already satisfied: scipy>=1.3.2 in c:\\program files\\python39\\lib\\site-packages (from scikit-learn->underthesea) (1.9.3)\n",
      "Requirement already satisfied: numpy>=1.17.3 in c:\\users\\phamp\\appdata\\roaming\\python\\python39\\site-packages (from scikit-learn->underthesea) (1.23.4)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip available: 22.3.1 -> 23.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install underthesea"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "K2BkS8AQryDY"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from underthesea import word_tokenize, pos_tag, sent_tokenize\n",
    "import regex\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "-w6OeQ4AryDb"
   },
   "outputs": [],
   "source": [
    "# https://underthesea.readthedocs.io/en/v1.1.5/readme.html\n",
    "# https://github.com/undertheseanlp/underthesea"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EnHQRMxCryDc"
   },
   "outputs": [],
   "source": [
    "##LOAD EMOJICON\n",
    "file = open('files/emojicon.txt', 'r', encoding=\"utf8\")\n",
    "emoji_lst = file.read().split('\\n')\n",
    "emoji_dict = {}\n",
    "for line in emoji_lst:\n",
    "    key, value = line.split('\\t')\n",
    "    emoji_dict[key] = str(value)\n",
    "file.close()\n",
    "#################\n",
    "#LOAD TEENCODE\n",
    "file = open('files/teencode.txt', 'r', encoding=\"utf8\")\n",
    "teen_lst = file.read().split('\\n')\n",
    "teen_dict = {}\n",
    "for line in teen_lst:\n",
    "    key, value = line.split('\\t')\n",
    "    teen_dict[key] = str(value)\n",
    "file.close()\n",
    "###############\n",
    "#LOAD TRANSLATE ENGLISH -> VNMESE\n",
    "file = open('files/english-vnmese.txt', 'r', encoding=\"utf8\")\n",
    "english_lst = file.read().split('\\n')\n",
    "english_dict = {}\n",
    "for line in english_lst:\n",
    "    key, value = line.split('\\t')\n",
    "    english_dict[key] = str(value)\n",
    "file.close()\n",
    "################\n",
    "#LOAD wrong words\n",
    "file = open('files/wrong-word.txt', 'r', encoding=\"utf8\")\n",
    "wrong_lst = file.read().split('\\n')\n",
    "file.close()\n",
    "#################\n",
    "#LOAD STOPWORDS\n",
    "file = open('files/vietnamese-stopwords.txt', 'r', encoding=\"utf8\")\n",
    "stopwords_lst = file.read().split('\\n')\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QBoO69oWryDc"
   },
   "outputs": [],
   "source": [
    "def process_text(text, emoji_dict, teen_dict, wrong_lst):\n",
    "    document = text.lower()\n",
    "    document = document.replace(\"’\",'')\n",
    "    document = regex.sub(r'\\.+', \".\", document)\n",
    "    new_sentence =''\n",
    "    for sentence in sent_tokenize(document):\n",
    "        # if not(sentence.isascii()):\n",
    "        ###### CONVERT EMOJICON\n",
    "        sentence = ''.join(emoji_dict[word]+' ' if word in emoji_dict else word for word in list(sentence))\n",
    "        ###### CONVERT TEENCODE\n",
    "        sentence = ' '.join(teen_dict[word] if word in teen_dict else word for word in sentence.split())\n",
    "        ###### DEL Punctuation & Numbers\n",
    "        pattern = r'(?i)\\b[a-záàảãạăắằẳẵặâấầẩẫậéèẻẽẹêếềểễệóòỏõọôốồổỗộơớờởỡợíìỉĩịúùủũụưứừửữựýỳỷỹỵđ]+\\b'\n",
    "        sentence = ' '.join(regex.findall(pattern,sentence))\n",
    "        ###### DEL wrong words   \n",
    "        sentence = ' '.join('' if word in wrong_lst else word for word in sentence.split())\n",
    "        new_sentence = new_sentence+ sentence + '. '                    \n",
    "    document = new_sentence  \n",
    "    #print(document)\n",
    "    ###### DEL excess blank space\n",
    "    document = regex.sub(r'\\s+', ' ', document).strip()\n",
    "    return document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "k896J_YKryDd"
   },
   "outputs": [],
   "source": [
    "example = '''Đầu năm vk ck tôi đi ctác ở sg ít ngày. \n",
    "Chúng tôi ở ks XXX. Ks ổn 👍, 😊. \n",
    "Phục vụ tốt chăm sóc nhiệt tình. \n",
    "Buffet ngon nhiều món. Phòng sạch sẽ.đầy đủ tiện nghi, view đẹp hướng ra sông sg.  \n",
    "Nhân viên thái độ phục vụ tốt 💙. Vị trí trung tâm tiện cho di chuyển thăm quan.'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0dTlk75JryDe"
   },
   "outputs": [],
   "source": [
    "document = process_text(example, emoji_dict, teen_dict, wrong_lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1MEKFTiKryDe"
   },
   "outputs": [],
   "source": [
    "# Chuẩn hóa unicode tiếng việt\n",
    "def loaddicchar():\n",
    "    uniChars = \"àáảãạâầấẩẫậăằắẳẵặèéẻẽẹêềếểễệđìíỉĩịòóỏõọôồốổỗộơờớởỡợùúủũụưừứửữựỳýỷỹỵÀÁẢÃẠÂẦẤẨẪẬĂẰẮẲẴẶÈÉẺẼẸÊỀẾỂỄỆĐÌÍỈĨỊÒÓỎÕỌÔỒỐỔỖỘƠỜỚỞỠỢÙÚỦŨỤƯỪỨỬỮỰỲÝỶỸỴÂĂĐÔƠƯ\"\n",
    "    unsignChars = \"aaaaaaaaaaaaaaaaaeeeeeeeeeeediiiiiooooooooooooooooouuuuuuuuuuuyyyyyAAAAAAAAAAAAAAAAAEEEEEEEEEEEDIIIOOOOOOOOOOOOOOOOOOOUUUUUUUUUUUYYYYYAADOOU\"\n",
    "\n",
    "    dic = {}\n",
    "    char1252 = 'à|á|ả|ã|ạ|ầ|ấ|ẩ|ẫ|ậ|ằ|ắ|ẳ|ẵ|ặ|è|é|ẻ|ẽ|ẹ|ề|ế|ể|ễ|ệ|ì|í|ỉ|ĩ|ị|ò|ó|ỏ|õ|ọ|ồ|ố|ổ|ỗ|ộ|ờ|ớ|ở|ỡ|ợ|ù|ú|ủ|ũ|ụ|ừ|ứ|ử|ữ|ự|ỳ|ý|ỷ|ỹ|ỵ|À|Á|Ả|Ã|Ạ|Ầ|Ấ|Ẩ|Ẫ|Ậ|Ằ|Ắ|Ẳ|Ẵ|Ặ|È|É|Ẻ|Ẽ|Ẹ|Ề|Ế|Ể|Ễ|Ệ|Ì|Í|Ỉ|Ĩ|Ị|Ò|Ó|Ỏ|Õ|Ọ|Ồ|Ố|Ổ|Ỗ|Ộ|Ờ|Ớ|Ở|Ỡ|Ợ|Ù|Ú|Ủ|Ũ|Ụ|Ừ|Ứ|Ử|Ữ|Ự|Ỳ|Ý|Ỷ|Ỹ|Ỵ'.split(\n",
    "        '|')\n",
    "    charutf8 = \"à|á|ả|ã|ạ|ầ|ấ|ẩ|ẫ|ậ|ằ|ắ|ẳ|ẵ|ặ|è|é|ẻ|ẽ|ẹ|ề|ế|ể|ễ|ệ|ì|í|ỉ|ĩ|ị|ò|ó|ỏ|õ|ọ|ồ|ố|ổ|ỗ|ộ|ờ|ớ|ở|ỡ|ợ|ù|ú|ủ|ũ|ụ|ừ|ứ|ử|ữ|ự|ỳ|ý|ỷ|ỹ|ỵ|À|Á|Ả|Ã|Ạ|Ầ|Ấ|Ẩ|Ẫ|Ậ|Ằ|Ắ|Ẳ|Ẵ|Ặ|È|É|Ẻ|Ẽ|Ẹ|Ề|Ế|Ể|Ễ|Ệ|Ì|Í|Ỉ|Ĩ|Ị|Ò|Ó|Ỏ|Õ|Ọ|Ồ|Ố|Ổ|Ỗ|Ộ|Ờ|Ớ|Ở|Ỡ|Ợ|Ù|Ú|Ủ|Ũ|Ụ|Ừ|Ứ|Ử|Ữ|Ự|Ỳ|Ý|Ỷ|Ỹ|Ỵ\".split(\n",
    "        '|')\n",
    "    for i in range(len(char1252)):\n",
    "        dic[char1252[i]] = charutf8[i]\n",
    "    return dic\n",
    " \n",
    "# Đưa toàn bộ dữ liệu qua hàm này để chuẩn hóa lại\n",
    "def covert_unicode(txt):\n",
    "    dicchar = loaddicchar()\n",
    "    return regex.sub(\n",
    "        r'à|á|ả|ã|ạ|ầ|ấ|ẩ|ẫ|ậ|ằ|ắ|ẳ|ẵ|ặ|è|é|ẻ|ẽ|ẹ|ề|ế|ể|ễ|ệ|ì|í|ỉ|ĩ|ị|ò|ó|ỏ|õ|ọ|ồ|ố|ổ|ỗ|ộ|ờ|ớ|ở|ỡ|ợ|ù|ú|ủ|ũ|ụ|ừ|ứ|ử|ữ|ự|ỳ|ý|ỷ|ỹ|ỵ|À|Á|Ả|Ã|Ạ|Ầ|Ấ|Ẩ|Ẫ|Ậ|Ằ|Ắ|Ẳ|Ẵ|Ặ|È|É|Ẻ|Ẽ|Ẹ|Ề|Ế|Ể|Ễ|Ệ|Ì|Í|Ỉ|Ĩ|Ị|Ò|Ó|Ỏ|Õ|Ọ|Ồ|Ố|Ổ|Ỗ|Ộ|Ờ|Ớ|Ở|Ỡ|Ợ|Ù|Ú|Ủ|Ũ|Ụ|Ừ|Ứ|Ử|Ữ|Ự|Ỳ|Ý|Ỷ|Ỹ|Ỵ',\n",
    "        lambda x: dicchar[x.group()], txt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IhM3oFS8ryDf"
   },
   "outputs": [],
   "source": [
    "document = covert_unicode(document)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nChQz0RiryDg"
   },
   "outputs": [],
   "source": [
    "def process_special_word(text):\n",
    "    new_text = ''\n",
    "    text_lst = text.split()\n",
    "    i= 0\n",
    "    if 'không' in text_lst:\n",
    "        while i <= len(text_lst) - 1:\n",
    "            word = text_lst[i]\n",
    "            #print(word)\n",
    "            #print(i)\n",
    "            if  word == 'không':\n",
    "                next_idx = i+1\n",
    "                if next_idx <= len(text_lst) -1:\n",
    "                    word = word +'_'+ text_lst[next_idx]\n",
    "                i= next_idx + 1\n",
    "            else:\n",
    "                i = i+1\n",
    "            new_text = new_text + word + ' '\n",
    "    else:\n",
    "        new_text = text\n",
    "    return new_text.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 53
    },
    "executionInfo": {
     "elapsed": 12,
     "status": "ok",
     "timestamp": 1668673673754,
     "user": {
      "displayName": "Phuong Khuat Thuy",
      "userId": "16807426118474640783"
     },
     "user_tz": -420
    },
    "id": "fOEspKNjryDg",
    "outputId": "6fd2d25c-ead3-4fc8-a30d-e62f8b456b0b"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'đầu năm vợ chồng tôi đi công tác ở sài gòn ít ngày. chúng tôi ở khách sạn . khách sạn ổn thích cười. phục vụ tốt chăm sóc nhiệt tình. nhiều món. phòng sạch sẽ đầy đủ tiện đẹp hướng sông . nhân viên thái độ phục vụ tốt yêu. vị trí tâm tiện cho di chuyển thăm quan.'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = process_special_word(document)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cb4HTaNQryDh"
   },
   "outputs": [],
   "source": [
    "def process_postag_thesea(text):\n",
    "    new_document = ''\n",
    "    for sentence in sent_tokenize(text):\n",
    "        sentence = sentence.replace('.','')\n",
    "        ###### POS tag\n",
    "        lst_word_type = ['A','AB','V','VB','VY','R']\n",
    "        sentence = ' '.join( word[0] if word[1].upper() in lst_word_type else '' for word in pos_tag(process_special_word(word_tokenize(sentence, format=\"text\"))))\n",
    "        new_document = new_document + sentence + ' '\n",
    "    ###### DEL excess blank space\n",
    "    new_document = regex.sub(r'\\s+', ' ', new_document).strip()\n",
    "    return new_document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LY8ojbejryDh"
   },
   "outputs": [],
   "source": [
    "document = process_postag_thesea(document)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "executionInfo": {
     "elapsed": 11,
     "status": "ok",
     "timestamp": 1668673673755,
     "user": {
      "displayName": "Phuong Khuat Thuy",
      "userId": "16807426118474640783"
     },
     "user_tz": -420
    },
    "id": "fB8f-uuQryDi",
    "outputId": "07667177-5590-447b-f237-e866a165ea2c"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'đi công_tác ít ổn thích cười tốt nhiều sạch_sẽ tiện đẹp phục_vụ tốt yêu tiện di_chuyển thăm'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ip_xMlXgryDi"
   },
   "outputs": [],
   "source": [
    "def remove_stopword(text, stopwords):\n",
    "    ###### REMOVE stop words\n",
    "    document = ' '.join('' if word in stopwords else word for word in text.split())\n",
    "    #print(document)\n",
    "    ###### DEL excess blank space\n",
    "    document = regex.sub(r'\\s+', ' ', document).strip()\n",
    "    return document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "executionInfo": {
     "elapsed": 11,
     "status": "ok",
     "timestamp": 1668673673756,
     "user": {
      "displayName": "Phuong Khuat Thuy",
      "userId": "16807426118474640783"
     },
     "user_tz": -420
    },
    "id": "F3_0ruTYryDi",
    "outputId": "375b22d2-8ee2-42ed-f1ec-6151f50d34ae"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'công_tác ổn thích cười tốt sạch_sẽ tiện đẹp phục_vụ tốt yêu tiện di_chuyển thăm'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "document = remove_stopword(document, stopwords_lst)\n",
    "document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UlZhA4_AryDj"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
