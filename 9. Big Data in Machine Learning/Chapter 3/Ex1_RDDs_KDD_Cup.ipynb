{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7d9fe306-2e2b-4d60-b92f-a5758facd87f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fed5721e-f35b-4c64-b61c-391cd21ef8a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark\n",
    "from pyspark import SparkContext\n",
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ae4754f9-bc7f-4af7-8eeb-34e6d11cf5f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "sc = SparkContext()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "30d503d2-2f14-47bb-8f6a-fdbc7c1ad47c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#1.\n",
    "file = \"kddcup.data_10_percent.gz\"\n",
    "data = sc.textFile(file, minPartitions=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "64032644-1c00-459f-98e5-d82bd66de3d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lines: 494021\n"
     ]
    }
   ],
   "source": [
    "#2. \n",
    "print(\"Lines:\", data.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "6da1516d-e5b2-4c0c-b1d1-da8c5d6aa9ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['0,tcp,http,SF,181,5450,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,8,8,0.00,0.00,0.00,0.00,1.00,0.00,0.00,9,9,1.00,0.00,0.11,0.00,0.00,0.00,0.00,0.00,normal.',\n",
       " '0,tcp,http,SF,239,486,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,8,8,0.00,0.00,0.00,0.00,1.00,0.00,0.00,19,19,1.00,0.00,0.05,0.00,0.00,0.00,0.00,0.00,normal.',\n",
       " '0,tcp,http,SF,235,1337,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,8,8,0.00,0.00,0.00,0.00,1.00,0.00,0.00,29,29,1.00,0.00,0.03,0.00,0.00,0.00,0.00,0.00,normal.']"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#3.\n",
    "data.take(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "431cd162-6671-43ec-be4f-75ebf73772b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0,tcp,http,SF,181,5450,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,8,8,0.00,0.00,0.00,0.00,1.00,0.00,0.00,9,9,1.00,0.00,0.11,0.00,0.00,0.00,0.00,0.00,normal.'"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.first()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "fce7a9a2-a513-4f73-aa00-7fd8b2ffc966",
   "metadata": {},
   "outputs": [],
   "source": [
    "#4.\n",
    "normal_data = data.filter(lambda x: 'normal.' in x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "55eda2d1-ac6a-4f3b-86e1-1d6e5094d393",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 97278 'normal's\n",
      "Time to count: 1.789 seconds\n"
     ]
    }
   ],
   "source": [
    "#5.\n",
    "from time import time\n",
    "t0 = time()\n",
    "normal_count = normal_data.count()\n",
    "t1 = time() - t0\n",
    "print(\"There are\", normal_count, \"'normal's\")\n",
    "print(\"Time to count:\", format(round(t1,3)), \"seconds\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "0440b5f5-f8fa-4dc2-a993-2b441b7bdd3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data collected in 2.898 seconds\n"
     ]
    }
   ],
   "source": [
    "#6. Array\n",
    "t0 = time()\n",
    "array_data = data.collect()\n",
    "t1 = time() - t0\n",
    "print(\"Data collected in\", round(t1,3), \"seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "e3cddd44-0125-4436-81f0-9cc0ff2c913b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample size is 49387 of 494021\n"
     ]
    }
   ],
   "source": [
    "#7. \n",
    "data_sample = data.sample(False, 0.1, 42)\n",
    "# parameter 1: the sampling is done with replacement or not\n",
    "# parameter 2: the sample size as a fraction. \n",
    "# parameter 3: [optionally] provide a random seed.\n",
    "sample_size = data_sample.count()\n",
    "total_size = data.count()\n",
    "print(\"Sample size is\", sample_size, \"of\", total_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "9aed7702-34b3-4bc7-bfb2-0b2d3739f1d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample with normal size is 9733\n",
      "The ratio of 'normal' interactions is  0.197\n",
      "Count done in 1.843 seconds\n"
     ]
    }
   ],
   "source": [
    "#8.\n",
    "sample_normal_tags = data_sample.filter(lambda x: \"normal.\" in x)\n",
    "t0 = time()\n",
    "sample_normal_tags_count = sample_normal_tags.count()\n",
    "tt = time() - t0\n",
    "sample_normal_ratio = sample_normal_tags_count / float(sample_size)\n",
    "print(\"Sample with normal size is\", sample_normal_tags_count)\n",
    "print(\"The ratio of 'normal' interactions is \", round(sample_normal_ratio,3))\n",
    "print(\"Count done in\", round(tt,3) ,\"seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "605f946c-6c6e-4fe5-8863-9d17f9fd2926",
   "metadata": {},
   "outputs": [],
   "source": [
    "#9. \n",
    "sample_without_normal = data_sample.subtract(sample_normal_tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "789cd23f-8ed0-40e6-a356-4061920d658a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample without normal size is 39654\n"
     ]
    }
   ],
   "source": [
    "print(\"Sample without normal size is\", sample_without_normal.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "cd126fba-aae5-441a-ab43-7f676ed24d72",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['0,icmp,ecr_i,SF,1032,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,509,509,0.00,0.00,0.00,0.00,1.00,0.00,0.00,255,255,1.00,0.00,1.00,0.00,0.00,0.00,0.00,0.00,smurf.']"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_without_normal.take(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "b85730ec-0049-45da-8b84-863bc39873f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#10. array_RDD \n",
    "array_RDD = data.map(lambda x: x.split(\",\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "fcc8c55c-9850-4036-907e-acef6cb0c591",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['0',\n",
       " 'tcp',\n",
       " 'http',\n",
       " 'SF',\n",
       " '181',\n",
       " '5450',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '1',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '8',\n",
       " '8',\n",
       " '0.00',\n",
       " '0.00',\n",
       " '0.00',\n",
       " '0.00',\n",
       " '1.00',\n",
       " '0.00',\n",
       " '0.00',\n",
       " '9',\n",
       " '9',\n",
       " '1.00',\n",
       " '0.00',\n",
       " '0.11',\n",
       " '0.00',\n",
       " '0.00',\n",
       " '0.00',\n",
       " '0.00',\n",
       " '0.00',\n",
       " 'normal.']"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "array_RDD.first()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "497bbfff-855f-4177-bbe6-5f0567d256d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['tcp', 'udp', 'icmp']"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#11.\n",
    "protocols = array_RDD.map(lambda x: x[1]).distinct()\n",
    "protocols.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "f3c42e8e-8f5e-44ec-9598-fd8b64e2d005",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Protocol: 3\n"
     ]
    }
   ],
   "source": [
    "print(\"Protocol:\", protocols.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "fc815764-fd58-4328-bafb-2af60ad0384c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['http',\n",
       " 'smtp',\n",
       " 'finger',\n",
       " 'domain_u',\n",
       " 'auth',\n",
       " 'telnet',\n",
       " 'ftp',\n",
       " 'eco_i',\n",
       " 'ntp_u',\n",
       " 'ecr_i',\n",
       " 'other',\n",
       " 'private',\n",
       " 'pop_3',\n",
       " 'ftp_data',\n",
       " 'rje',\n",
       " 'time',\n",
       " 'mtp',\n",
       " 'link',\n",
       " 'remote_job',\n",
       " 'gopher',\n",
       " 'ssh',\n",
       " 'name',\n",
       " 'whois',\n",
       " 'domain',\n",
       " 'login',\n",
       " 'imap4',\n",
       " 'daytime',\n",
       " 'ctf',\n",
       " 'nntp',\n",
       " 'shell',\n",
       " 'IRC',\n",
       " 'nnsp',\n",
       " 'http_443',\n",
       " 'exec',\n",
       " 'printer',\n",
       " 'efs',\n",
       " 'courier',\n",
       " 'uucp',\n",
       " 'klogin',\n",
       " 'kshell',\n",
       " 'echo',\n",
       " 'discard',\n",
       " 'systat',\n",
       " 'supdup',\n",
       " 'iso_tsap',\n",
       " 'hostnames',\n",
       " 'csnet_ns',\n",
       " 'pop_2',\n",
       " 'sunrpc',\n",
       " 'uucp_path',\n",
       " 'netbios_ns',\n",
       " 'netbios_ssn',\n",
       " 'netbios_dgm',\n",
       " 'sql_net',\n",
       " 'vmnet',\n",
       " 'bgp',\n",
       " 'Z39_50',\n",
       " 'ldap',\n",
       " 'netstat',\n",
       " 'urh_i',\n",
       " 'X11',\n",
       " 'urp_i',\n",
       " 'pm_dump',\n",
       " 'tftp_u',\n",
       " 'tim_i',\n",
       " 'red_i']"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#12\n",
    "services = array_RDD.map(lambda x: x[2]).distinct()\n",
    "services.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "d005286e-2eb2-4544-a762-11a2aaa91826",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Service: 66\n"
     ]
    }
   ],
   "source": [
    "print(\"Service:\", services.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "db2a98e4-ce93-42f8-a26f-7311ae811a37",
   "metadata": {},
   "outputs": [],
   "source": [
    "#13\n",
    "product = protocols.cartesian(services).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "d34cad7a-6650-402a-b58a-397bc942f749",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('tcp', 'http'),\n",
       " ('tcp', 'smtp'),\n",
       " ('tcp', 'finger'),\n",
       " ('tcp', 'domain_u'),\n",
       " ('tcp', 'auth'),\n",
       " ('tcp', 'telnet'),\n",
       " ('tcp', 'ftp'),\n",
       " ('tcp', 'eco_i'),\n",
       " ('tcp', 'ntp_u'),\n",
       " ('tcp', 'ecr_i'),\n",
       " ('tcp', 'other'),\n",
       " ('tcp', 'private'),\n",
       " ('tcp', 'pop_3'),\n",
       " ('tcp', 'ftp_data'),\n",
       " ('tcp', 'rje'),\n",
       " ('tcp', 'time'),\n",
       " ('tcp', 'mtp'),\n",
       " ('tcp', 'link'),\n",
       " ('tcp', 'remote_job'),\n",
       " ('tcp', 'gopher'),\n",
       " ('tcp', 'ssh'),\n",
       " ('tcp', 'name'),\n",
       " ('tcp', 'whois'),\n",
       " ('tcp', 'domain'),\n",
       " ('tcp', 'login'),\n",
       " ('tcp', 'imap4'),\n",
       " ('tcp', 'daytime'),\n",
       " ('tcp', 'ctf'),\n",
       " ('tcp', 'nntp'),\n",
       " ('tcp', 'shell'),\n",
       " ('tcp', 'IRC'),\n",
       " ('tcp', 'nnsp'),\n",
       " ('tcp', 'http_443'),\n",
       " ('tcp', 'exec'),\n",
       " ('tcp', 'printer'),\n",
       " ('tcp', 'efs'),\n",
       " ('tcp', 'courier'),\n",
       " ('tcp', 'uucp'),\n",
       " ('tcp', 'klogin'),\n",
       " ('tcp', 'kshell'),\n",
       " ('tcp', 'echo'),\n",
       " ('tcp', 'discard'),\n",
       " ('tcp', 'systat'),\n",
       " ('tcp', 'supdup'),\n",
       " ('tcp', 'iso_tsap'),\n",
       " ('tcp', 'hostnames'),\n",
       " ('tcp', 'csnet_ns'),\n",
       " ('tcp', 'pop_2'),\n",
       " ('tcp', 'sunrpc'),\n",
       " ('tcp', 'uucp_path'),\n",
       " ('tcp', 'netbios_ns'),\n",
       " ('tcp', 'netbios_ssn'),\n",
       " ('tcp', 'netbios_dgm'),\n",
       " ('tcp', 'sql_net'),\n",
       " ('tcp', 'vmnet'),\n",
       " ('tcp', 'bgp'),\n",
       " ('tcp', 'Z39_50'),\n",
       " ('tcp', 'ldap'),\n",
       " ('tcp', 'netstat'),\n",
       " ('tcp', 'urh_i'),\n",
       " ('tcp', 'X11'),\n",
       " ('tcp', 'urp_i'),\n",
       " ('tcp', 'pm_dump'),\n",
       " ('tcp', 'tftp_u'),\n",
       " ('tcp', 'tim_i'),\n",
       " ('tcp', 'red_i'),\n",
       " ('udp', 'http'),\n",
       " ('icmp', 'http'),\n",
       " ('udp', 'smtp'),\n",
       " ('udp', 'finger'),\n",
       " ('icmp', 'smtp'),\n",
       " ('icmp', 'finger'),\n",
       " ('udp', 'domain_u'),\n",
       " ('udp', 'auth'),\n",
       " ('udp', 'telnet'),\n",
       " ('udp', 'ftp'),\n",
       " ('icmp', 'domain_u'),\n",
       " ('icmp', 'auth'),\n",
       " ('icmp', 'telnet'),\n",
       " ('icmp', 'ftp'),\n",
       " ('udp', 'eco_i'),\n",
       " ('udp', 'ntp_u'),\n",
       " ('udp', 'ecr_i'),\n",
       " ('udp', 'other'),\n",
       " ('udp', 'private'),\n",
       " ('udp', 'pop_3'),\n",
       " ('udp', 'ftp_data'),\n",
       " ('udp', 'rje'),\n",
       " ('icmp', 'eco_i'),\n",
       " ('icmp', 'ntp_u'),\n",
       " ('icmp', 'ecr_i'),\n",
       " ('icmp', 'other'),\n",
       " ('icmp', 'private'),\n",
       " ('icmp', 'pop_3'),\n",
       " ('icmp', 'ftp_data'),\n",
       " ('icmp', 'rje'),\n",
       " ('udp', 'time'),\n",
       " ('udp', 'mtp'),\n",
       " ('udp', 'link'),\n",
       " ('udp', 'remote_job'),\n",
       " ('udp', 'gopher'),\n",
       " ('udp', 'ssh'),\n",
       " ('udp', 'name'),\n",
       " ('udp', 'whois'),\n",
       " ('udp', 'domain'),\n",
       " ('udp', 'login'),\n",
       " ('udp', 'imap4'),\n",
       " ('udp', 'daytime'),\n",
       " ('udp', 'ctf'),\n",
       " ('udp', 'nntp'),\n",
       " ('udp', 'shell'),\n",
       " ('udp', 'IRC'),\n",
       " ('icmp', 'time'),\n",
       " ('icmp', 'mtp'),\n",
       " ('icmp', 'link'),\n",
       " ('icmp', 'remote_job'),\n",
       " ('icmp', 'gopher'),\n",
       " ('icmp', 'ssh'),\n",
       " ('icmp', 'name'),\n",
       " ('icmp', 'whois'),\n",
       " ('icmp', 'domain'),\n",
       " ('icmp', 'login'),\n",
       " ('icmp', 'imap4'),\n",
       " ('icmp', 'daytime'),\n",
       " ('icmp', 'ctf'),\n",
       " ('icmp', 'nntp'),\n",
       " ('icmp', 'shell'),\n",
       " ('icmp', 'IRC'),\n",
       " ('udp', 'nnsp'),\n",
       " ('udp', 'http_443'),\n",
       " ('udp', 'exec'),\n",
       " ('udp', 'printer'),\n",
       " ('udp', 'efs'),\n",
       " ('udp', 'courier'),\n",
       " ('udp', 'uucp'),\n",
       " ('udp', 'klogin'),\n",
       " ('udp', 'kshell'),\n",
       " ('udp', 'echo'),\n",
       " ('udp', 'discard'),\n",
       " ('udp', 'systat'),\n",
       " ('udp', 'supdup'),\n",
       " ('udp', 'iso_tsap'),\n",
       " ('udp', 'hostnames'),\n",
       " ('udp', 'csnet_ns'),\n",
       " ('udp', 'pop_2'),\n",
       " ('udp', 'sunrpc'),\n",
       " ('udp', 'uucp_path'),\n",
       " ('udp', 'netbios_ns'),\n",
       " ('udp', 'netbios_ssn'),\n",
       " ('udp', 'netbios_dgm'),\n",
       " ('udp', 'sql_net'),\n",
       " ('udp', 'vmnet'),\n",
       " ('udp', 'bgp'),\n",
       " ('udp', 'Z39_50'),\n",
       " ('udp', 'ldap'),\n",
       " ('udp', 'netstat'),\n",
       " ('udp', 'urh_i'),\n",
       " ('udp', 'X11'),\n",
       " ('udp', 'urp_i'),\n",
       " ('udp', 'pm_dump'),\n",
       " ('icmp', 'nnsp'),\n",
       " ('icmp', 'http_443'),\n",
       " ('icmp', 'exec'),\n",
       " ('icmp', 'printer'),\n",
       " ('icmp', 'efs'),\n",
       " ('icmp', 'courier'),\n",
       " ('icmp', 'uucp'),\n",
       " ('icmp', 'klogin'),\n",
       " ('icmp', 'kshell'),\n",
       " ('icmp', 'echo'),\n",
       " ('icmp', 'discard'),\n",
       " ('icmp', 'systat'),\n",
       " ('icmp', 'supdup'),\n",
       " ('icmp', 'iso_tsap'),\n",
       " ('icmp', 'hostnames'),\n",
       " ('icmp', 'csnet_ns'),\n",
       " ('icmp', 'pop_2'),\n",
       " ('icmp', 'sunrpc'),\n",
       " ('icmp', 'uucp_path'),\n",
       " ('icmp', 'netbios_ns'),\n",
       " ('icmp', 'netbios_ssn'),\n",
       " ('icmp', 'netbios_dgm'),\n",
       " ('icmp', 'sql_net'),\n",
       " ('icmp', 'vmnet'),\n",
       " ('icmp', 'bgp'),\n",
       " ('icmp', 'Z39_50'),\n",
       " ('icmp', 'ldap'),\n",
       " ('icmp', 'netstat'),\n",
       " ('icmp', 'urh_i'),\n",
       " ('icmp', 'X11'),\n",
       " ('icmp', 'urp_i'),\n",
       " ('icmp', 'pm_dump'),\n",
       " ('udp', 'tftp_u'),\n",
       " ('udp', 'tim_i'),\n",
       " ('udp', 'red_i'),\n",
       " ('icmp', 'tftp_u'),\n",
       " ('icmp', 'tim_i'),\n",
       " ('icmp', 'red_i')]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "0d65df7c-6635-454d-9436-7a05488bad82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 198 combinations of protocol X service\n"
     ]
    }
   ],
   "source": [
    "print(\"There are\", len(product), \"combinations of protocol X service\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "bf52669f-3adf-425c-a60c-37be2faf13a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "array_RDD.getNumPartitions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "2c9e3584-6cf1-4a65-9ce7-d65c88f8116d",
   "metadata": {},
   "outputs": [
    {
     "ename": "Py4JJavaError",
     "evalue": "An error occurred while calling o534.saveAsTextFile.\n: org.apache.hadoop.mapred.FileAlreadyExistsException: Output directory file:/C:/Users/AW/OneDrive/Phu/Python/9. Big Data in Machine Learning/BaiTap/Chapter 3/kdd_cup already exists\r\n\tat org.apache.hadoop.mapred.FileOutputFormat.checkOutputSpecs(FileOutputFormat.java:131)\r\n\tat org.apache.spark.internal.io.HadoopMapRedWriteConfigUtil.assertConf(SparkHadoopWriter.scala:299)\r\n\tat org.apache.spark.internal.io.SparkHadoopWriter$.write(SparkHadoopWriter.scala:71)\r\n\tat org.apache.spark.rdd.PairRDDFunctions.$anonfun$saveAsHadoopDataset$1(PairRDDFunctions.scala:1091)\r\n\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\r\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\r\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)\r\n\tat org.apache.spark.rdd.RDD.withScope(RDD.scala:407)\r\n\tat org.apache.spark.rdd.PairRDDFunctions.saveAsHadoopDataset(PairRDDFunctions.scala:1089)\r\n\tat org.apache.spark.rdd.PairRDDFunctions.$anonfun$saveAsHadoopFile$4(PairRDDFunctions.scala:1062)\r\n\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\r\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\r\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)\r\n\tat org.apache.spark.rdd.RDD.withScope(RDD.scala:407)\r\n\tat org.apache.spark.rdd.PairRDDFunctions.saveAsHadoopFile(PairRDDFunctions.scala:1027)\r\n\tat org.apache.spark.rdd.PairRDDFunctions.$anonfun$saveAsHadoopFile$3(PairRDDFunctions.scala:1009)\r\n\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\r\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\r\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)\r\n\tat org.apache.spark.rdd.RDD.withScope(RDD.scala:407)\r\n\tat org.apache.spark.rdd.PairRDDFunctions.saveAsHadoopFile(PairRDDFunctions.scala:1008)\r\n\tat org.apache.spark.rdd.PairRDDFunctions.$anonfun$saveAsHadoopFile$2(PairRDDFunctions.scala:965)\r\n\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\r\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\r\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)\r\n\tat org.apache.spark.rdd.RDD.withScope(RDD.scala:407)\r\n\tat org.apache.spark.rdd.PairRDDFunctions.saveAsHadoopFile(PairRDDFunctions.scala:963)\r\n\tat org.apache.spark.rdd.RDD.$anonfun$saveAsTextFile$2(RDD.scala:1620)\r\n\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\r\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\r\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)\r\n\tat org.apache.spark.rdd.RDD.withScope(RDD.scala:407)\r\n\tat org.apache.spark.rdd.RDD.saveAsTextFile(RDD.scala:1620)\r\n\tat org.apache.spark.rdd.RDD.$anonfun$saveAsTextFile$1(RDD.scala:1606)\r\n\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\r\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\r\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)\r\n\tat org.apache.spark.rdd.RDD.withScope(RDD.scala:407)\r\n\tat org.apache.spark.rdd.RDD.saveAsTextFile(RDD.scala:1606)\r\n\tat org.apache.spark.api.java.JavaRDDLike.saveAsTextFile(JavaRDDLike.scala:564)\r\n\tat org.apache.spark.api.java.JavaRDDLike.saveAsTextFile$(JavaRDDLike.scala:563)\r\n\tat org.apache.spark.api.java.AbstractJavaRDDLike.saveAsTextFile(JavaRDDLike.scala:45)\r\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\r\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\r\n\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\r\n\tat java.base/java.lang.reflect.Method.invoke(Method.java:566)\r\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\r\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\r\n\tat py4j.Gateway.invoke(Gateway.java:282)\r\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\r\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\r\n\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\r\n\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\r\n\tat java.base/java.lang.Thread.run(Thread.java:834)\r\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mPy4JJavaError\u001b[0m                             Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[56], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m#15.\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[43marray_RDD\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msaveAsTextFile\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mkdd_cup\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mC:\\spark\\spark-3.5.0-bin-hadoop3\\python\\pyspark\\rdd.py:3425\u001b[0m, in \u001b[0;36mRDD.saveAsTextFile\u001b[1;34m(self, path, compressionCodecClass)\u001b[0m\n\u001b[0;32m   3423\u001b[0m     keyed\u001b[38;5;241m.\u001b[39m_jrdd\u001b[38;5;241m.\u001b[39mmap(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mctx\u001b[38;5;241m.\u001b[39m_jvm\u001b[38;5;241m.\u001b[39mBytesToString())\u001b[38;5;241m.\u001b[39msaveAsTextFile(path, compressionCodec)\n\u001b[0;32m   3424\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 3425\u001b[0m     \u001b[43mkeyed\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_jrdd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_jvm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mBytesToString\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msaveAsTextFile\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mC:\\spark\\spark-3.5.0-bin-hadoop3\\python\\lib\\py4j-0.10.9.7-src.zip\\py4j\\java_gateway.py:1322\u001b[0m, in \u001b[0;36mJavaMember.__call__\u001b[1;34m(self, *args)\u001b[0m\n\u001b[0;32m   1316\u001b[0m command \u001b[38;5;241m=\u001b[39m proto\u001b[38;5;241m.\u001b[39mCALL_COMMAND_NAME \u001b[38;5;241m+\u001b[39m\\\n\u001b[0;32m   1317\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcommand_header \u001b[38;5;241m+\u001b[39m\\\n\u001b[0;32m   1318\u001b[0m     args_command \u001b[38;5;241m+\u001b[39m\\\n\u001b[0;32m   1319\u001b[0m     proto\u001b[38;5;241m.\u001b[39mEND_COMMAND_PART\n\u001b[0;32m   1321\u001b[0m answer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgateway_client\u001b[38;5;241m.\u001b[39msend_command(command)\n\u001b[1;32m-> 1322\u001b[0m return_value \u001b[38;5;241m=\u001b[39m \u001b[43mget_return_value\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1323\u001b[0m \u001b[43m    \u001b[49m\u001b[43manswer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgateway_client\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtarget_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1325\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m temp_arg \u001b[38;5;129;01min\u001b[39;00m temp_args:\n\u001b[0;32m   1326\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(temp_arg, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_detach\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n",
      "File \u001b[1;32mC:\\spark\\spark-3.5.0-bin-hadoop3\\python\\lib\\py4j-0.10.9.7-src.zip\\py4j\\protocol.py:326\u001b[0m, in \u001b[0;36mget_return_value\u001b[1;34m(answer, gateway_client, target_id, name)\u001b[0m\n\u001b[0;32m    324\u001b[0m value \u001b[38;5;241m=\u001b[39m OUTPUT_CONVERTER[\u001b[38;5;28mtype\u001b[39m](answer[\u001b[38;5;241m2\u001b[39m:], gateway_client)\n\u001b[0;32m    325\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m answer[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m==\u001b[39m REFERENCE_TYPE:\n\u001b[1;32m--> 326\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m Py4JJavaError(\n\u001b[0;32m    327\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAn error occurred while calling \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39m\n\u001b[0;32m    328\u001b[0m         \u001b[38;5;28mformat\u001b[39m(target_id, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m, name), value)\n\u001b[0;32m    329\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    330\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m Py4JError(\n\u001b[0;32m    331\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAn error occurred while calling \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m. Trace:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{3}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39m\n\u001b[0;32m    332\u001b[0m         \u001b[38;5;28mformat\u001b[39m(target_id, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m, name, value))\n",
      "\u001b[1;31mPy4JJavaError\u001b[0m: An error occurred while calling o534.saveAsTextFile.\n: org.apache.hadoop.mapred.FileAlreadyExistsException: Output directory file:/C:/Users/AW/OneDrive/Phu/Python/9. Big Data in Machine Learning/BaiTap/Chapter 3/kdd_cup already exists\r\n\tat org.apache.hadoop.mapred.FileOutputFormat.checkOutputSpecs(FileOutputFormat.java:131)\r\n\tat org.apache.spark.internal.io.HadoopMapRedWriteConfigUtil.assertConf(SparkHadoopWriter.scala:299)\r\n\tat org.apache.spark.internal.io.SparkHadoopWriter$.write(SparkHadoopWriter.scala:71)\r\n\tat org.apache.spark.rdd.PairRDDFunctions.$anonfun$saveAsHadoopDataset$1(PairRDDFunctions.scala:1091)\r\n\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\r\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\r\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)\r\n\tat org.apache.spark.rdd.RDD.withScope(RDD.scala:407)\r\n\tat org.apache.spark.rdd.PairRDDFunctions.saveAsHadoopDataset(PairRDDFunctions.scala:1089)\r\n\tat org.apache.spark.rdd.PairRDDFunctions.$anonfun$saveAsHadoopFile$4(PairRDDFunctions.scala:1062)\r\n\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\r\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\r\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)\r\n\tat org.apache.spark.rdd.RDD.withScope(RDD.scala:407)\r\n\tat org.apache.spark.rdd.PairRDDFunctions.saveAsHadoopFile(PairRDDFunctions.scala:1027)\r\n\tat org.apache.spark.rdd.PairRDDFunctions.$anonfun$saveAsHadoopFile$3(PairRDDFunctions.scala:1009)\r\n\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\r\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\r\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)\r\n\tat org.apache.spark.rdd.RDD.withScope(RDD.scala:407)\r\n\tat org.apache.spark.rdd.PairRDDFunctions.saveAsHadoopFile(PairRDDFunctions.scala:1008)\r\n\tat org.apache.spark.rdd.PairRDDFunctions.$anonfun$saveAsHadoopFile$2(PairRDDFunctions.scala:965)\r\n\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\r\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\r\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)\r\n\tat org.apache.spark.rdd.RDD.withScope(RDD.scala:407)\r\n\tat org.apache.spark.rdd.PairRDDFunctions.saveAsHadoopFile(PairRDDFunctions.scala:963)\r\n\tat org.apache.spark.rdd.RDD.$anonfun$saveAsTextFile$2(RDD.scala:1620)\r\n\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\r\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\r\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)\r\n\tat org.apache.spark.rdd.RDD.withScope(RDD.scala:407)\r\n\tat org.apache.spark.rdd.RDD.saveAsTextFile(RDD.scala:1620)\r\n\tat org.apache.spark.rdd.RDD.$anonfun$saveAsTextFile$1(RDD.scala:1606)\r\n\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\r\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\r\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)\r\n\tat org.apache.spark.rdd.RDD.withScope(RDD.scala:407)\r\n\tat org.apache.spark.rdd.RDD.saveAsTextFile(RDD.scala:1606)\r\n\tat org.apache.spark.api.java.JavaRDDLike.saveAsTextFile(JavaRDDLike.scala:564)\r\n\tat org.apache.spark.api.java.JavaRDDLike.saveAsTextFile$(JavaRDDLike.scala:563)\r\n\tat org.apache.spark.api.java.AbstractJavaRDDLike.saveAsTextFile(JavaRDDLike.scala:45)\r\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\r\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\r\n\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\r\n\tat java.base/java.lang.reflect.Method.invoke(Method.java:566)\r\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\r\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\r\n\tat py4j.Gateway.invoke(Gateway.java:282)\r\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\r\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\r\n\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\r\n\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\r\n\tat java.base/java.lang.Thread.run(Thread.java:834)\r\n"
     ]
    }
   ],
   "source": [
    "#15.\n",
    "array_RDD.saveAsTextFile(\"kdd_cup\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51b78b02-2558-4726-9f6c-a2d5c954b73e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c575576f-d041-43b9-a887-d77f961fc9c1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
