{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "MhGbZVXumcwx"
      },
      "source": [
        "!apt update\n",
        "!apt-get install openjdk-11-jdk-headless -qq > /dev/null\n",
        "!wget -q http://archive.apache.org/dist/spark/spark-3.3.0/spark-3.3.0-bin-hadoop3.tgz\n",
        "!tar -xvf spark-3.3.0-bin-hadoop3.tgz\n",
        "!pip install -q findspark\n",
        "import os\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-11-openjdk-amd64\"\n",
        "os.environ[\"SPARK_HOME\"] = \"/content/spark-3.3.0-bin-hadoop3\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import findspark\n",
        "findspark.init()"
      ],
      "metadata": {
        "id": "lTSukfVFoM-4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FPAqiuGwmqmA"
      },
      "source": [
        "from pyspark.sql import SparkSession\n",
        "from pyspark.ml.feature import Tokenizer, RegexTokenizer\n",
        "from pyspark.sql.functions import col, udf\n",
        "from pyspark.sql.types import IntegerType\n",
        "from pyspark.ml.feature import StopWordsRemover\n",
        "from pyspark.ml.feature import CountVectorizer\n",
        "from pyspark.ml.feature import IDF, Tokenizer\n",
        "from pyspark.ml.feature import NGram"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XqwEY2jQmuHH"
      },
      "source": [
        "spark = SparkSession.builder.appName('nlp').getOrCreate()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Tokenizer"
      ],
      "metadata": {
        "id": "YrCbweEPp3Fo"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CMQZenS8m6tI"
      },
      "source": [
        "sentenceDataFrame = spark.createDataFrame([\n",
        "    (0, \"Hi I heard about Spark\"),\n",
        "    (1, \"I know Spark can work well with NLP\"),\n",
        "    (2, \"Logistic,regression,models,are,supervised\")\n",
        "], [\"id\", \"sentence\"])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7-XDJXnJm-wX",
        "outputId": "79825416-3515-47ea-d90a-76e9d6971ea1"
      },
      "source": [
        "sentenceDataFrame.show(truncate=False)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+---+-----------------------------------------+\n",
            "|id |sentence                                 |\n",
            "+---+-----------------------------------------+\n",
            "|0  |Hi I heard about Spark                   |\n",
            "|1  |I know Spark can work well with NLP      |\n",
            "|2  |Logistic,regression,models,are,supervised|\n",
            "+---+-----------------------------------------+\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "lejOkwfwp5-X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "lTCrkb8Xp6F3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Ocv_yo0ep7Pv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## StopWordsRemover"
      ],
      "metadata": {
        "id": "XNKjY8LEp7d_"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "vZGdhKEwqDWW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ZvG_c5plqZ7f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## N-Gram"
      ],
      "metadata": {
        "id": "VD9waIcaqabv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "wordDataFrame = spark.createDataFrame([\n",
        "    (0, [\"Hi\", \"I\", \"heard\", \"about\", \"Spark\"]),\n",
        "    (1, [\"I\", \"know\", \"Spark\", \"can\", \"work\", \"well\", \"with\", \"NLP\"]),\n",
        "    (2, [\"Logistic\", \"regression\", \"models\", \"are\", \"supervised\"])\n",
        "], [\"id\", \"words\"])"
      ],
      "metadata": {
        "id": "cCWDcz6HqbrW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "EZZ9zFsbqmjH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "8ZR5_Os5rVW4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## CountVectorizer"
      ],
      "metadata": {
        "id": "UnXR96teqnrH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Input data: Each row is a bag of words with a ID.\n",
        "df = spark.createDataFrame([\n",
        "    (0, \"a b c\".split(\" \")),\n",
        "    (1, \"a b b c a\".split(\" \")),\n",
        "    (2, \"a b d d a c c\".split(\" \"))\n",
        "], [\"id\", \"words\"])"
      ],
      "metadata": {
        "id": "OPYOfn_wqsh-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "M3L9xbPrq0dO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "75WUG1i6rSff"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## IF-IDF"
      ],
      "metadata": {
        "id": "2myQ1Qt1q3ce"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sentenceData = spark.createDataFrame([\n",
        "    (0.0, \"a b c\"),\n",
        "    (0.0, \"a b c a\"),\n",
        "    (1.0, \"a b d d a c c\")\n",
        "], [\"label\", \"sentence\"])\n",
        "sentenceData.show(truncate=False)"
      ],
      "metadata": {
        "id": "tVvyFJCrq4_f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ku8XMnGGrRXH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ltQBvkivrR8X"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}