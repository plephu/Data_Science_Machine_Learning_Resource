{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.8"
    },
    "colab": {
      "provenance": []
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "BnDjWL0AmexJ"
      },
      "source": [
        "!apt update\n",
        "!apt-get install openjdk-11-jdk-headless -qq > /dev/null\n",
        "!wget -q http://archive.apache.org/dist/spark/spark-3.3.0/spark-3.3.0-bin-hadoop3.tgz\n",
        "!tar -xvf spark-3.3.0-bin-hadoop3.tgz\n",
        "!pip install -q findspark\n",
        "import os\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-11-openjdk-amd64\"\n",
        "os.environ[\"SPARK_HOME\"] = \"/content/spark-3.3.0-bin-hadoop3\"\n",
        "import findspark\n",
        "findspark.init()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UfTeLiTXmcZe"
      },
      "source": [
        "import pyspark\n",
        "import os"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nMte4qJKms2A"
      },
      "source": [
        "from pyspark.sql import *"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4TCwjLYZmcZf"
      },
      "source": [
        "# cai dat va thiet lap bien moi truong nêu chay tren colab\n",
        "SUBMIT_ARGS = \"--packages graphframes:graphframes:0.8.2-spark3.2-s_2.12 pyspark-shell\"\n",
        "os.environ[\"PYSPARK_SUBMIT_ARGS\"] = SUBMIT_ARGS"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DHdc9sBamcZf",
        "outputId": "c2f037f7-6870-4427-90a2-8061c3d3c42c"
      },
      "source": [
        "conf = pyspark.SparkConf()\n",
        "sc = pyspark.SparkContext(conf=conf)\n",
        "print(sc._conf.getAll())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('spark.driver.extraJavaOptions', '-XX:+IgnoreUnrecognizedVMOptions --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.lang.invoke=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.base/java.net=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.util.concurrent=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.cs=ALL-UNNAMED --add-opens=java.base/sun.security.action=ALL-UNNAMED --add-opens=java.base/sun.util.calendar=ALL-UNNAMED --add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED'), ('spark.app.initial.jar.urls', 'spark://e0d1af586fc5:45951/jars/org.slf4j_slf4j-api-1.7.16.jar,spark://e0d1af586fc5:45951/jars/graphframes_graphframes-0.8.2-spark3.2-s_2.12.jar'), ('spark.executor.id', 'driver'), ('spark.driver.host', 'e0d1af586fc5'), ('spark.app.initial.file.urls', 'file:///root/.ivy2/jars/org.slf4j_slf4j-api-1.7.16.jar,file:///root/.ivy2/jars/graphframes_graphframes-0.8.2-spark3.2-s_2.12.jar'), ('spark.app.name', 'pyspark-shell'), ('spark.submit.pyFiles', '/root/.ivy2/jars/graphframes_graphframes-0.8.2-spark3.2-s_2.12.jar,/root/.ivy2/jars/org.slf4j_slf4j-api-1.7.16.jar'), ('spark.jars', 'file:///root/.ivy2/jars/graphframes_graphframes-0.8.2-spark3.2-s_2.12.jar,file:///root/.ivy2/jars/org.slf4j_slf4j-api-1.7.16.jar'), ('spark.driver.port', '45951'), ('spark.app.submitTime', '1690958021682'), ('spark.rdd.compress', 'True'), ('spark.executor.extraJavaOptions', '-XX:+IgnoreUnrecognizedVMOptions --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.lang.invoke=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.base/java.net=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.util.concurrent=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.cs=ALL-UNNAMED --add-opens=java.base/sun.security.action=ALL-UNNAMED --add-opens=java.base/sun.util.calendar=ALL-UNNAMED --add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED'), ('spark.repl.local.jars', 'file:///root/.ivy2/jars/graphframes_graphframes-0.8.2-spark3.2-s_2.12.jar,file:///root/.ivy2/jars/org.slf4j_slf4j-api-1.7.16.jar'), ('spark.serializer.objectStreamReset', '100'), ('spark.master', 'local[*]'), ('spark.app.startTime', '1690958022154'), ('spark.submit.deployMode', 'client'), ('spark.app.id', 'local-1690958024283'), ('spark.files', 'file:///root/.ivy2/jars/graphframes_graphframes-0.8.2-spark3.2-s_2.12.jar,file:///root/.ivy2/jars/org.slf4j_slf4j-api-1.7.16.jar'), ('spark.ui.showConsoleProgress', 'true')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ITkhYpXTmcZh"
      },
      "source": [
        "### Tạo graph"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8ahsqWKPmcZh"
      },
      "source": [
        "from graphframes import *"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lLvugwrFmcZh"
      },
      "source": [
        "spark = SparkSession(sc)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HANjBSErmcZi"
      },
      "source": [
        "vertices = spark.createDataFrame([('1', 'Carter', 50),\n",
        "                                  ('2', 'May', 26),\n",
        "                                 ('3', 'Mills', 80),\n",
        "                                  ('4', 'Hood', 65),\n",
        "                                  ('5', 'Banks', 93),\n",
        "                                 ('98', 'Berg', 28),\n",
        "                                 ('99', 'Page', 16)],\n",
        "                                 ['id', 'name', 'age'])\n",
        "edges = spark.createDataFrame([('1', '2', 'friend'),\n",
        "                               ('1', '98', 'friend'),\n",
        "                               ('2', '1', 'friend'),\n",
        "                              ('3', '1', 'friend'),\n",
        "                              ('1', '3', 'friend'),\n",
        "                               ('2', '3', 'follows'),\n",
        "                               ('3', '4', 'friend'),\n",
        "                               ('4', '3', 'friend'),\n",
        "                               ('5', '3', 'friend'),\n",
        "                               ('3', '5', 'friend'),\n",
        "                               ('4', '5', 'follows'),\n",
        "                              ('98', '99', 'friend'),\n",
        "                              ('99', '98', 'friend')],\n",
        "                              ['src', 'dst', 'type'])"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}