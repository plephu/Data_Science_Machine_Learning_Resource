{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "c0JvcgTY_23t"
   },
   "outputs": [],
   "source": [
    "# !apt update\n",
    "# !apt-get install openjdk-11-jdk-headless -qq > /dev/null\n",
    "# !wget -q http://archive.apache.org/dist/spark/spark-3.3.0/spark-3.3.0-bin-hadoop3.tgz\n",
    "# !tar -xvf spark-3.3.0-bin-hadoop3.tgz\n",
    "# !pip install -q findspark\n",
    "# import os\n",
    "# os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-11-openjdk-amd64\"\n",
    "# os.environ[\"SPARK_HOME\"] = \"/content/spark-3.3.0-bin-hadoop3\"\n",
    "import findspark\n",
    "findspark.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dumPUEuh_-nY",
    "outputId": "64b00a89-73b7-4ead-df9c-238627d301b3"
   },
   "outputs": [],
   "source": [
    "# from google.colab import drive\n",
    "# drive.mount('/content/gdrive', force_remount=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RH0SEBw0ABPH",
    "outputId": "75cc3807-951f-4bef-c6f6-87e6fa70578d"
   },
   "outputs": [],
   "source": [
    "# %cd '/content/gdrive/My Drive/LDS9/Practice/Chapter6/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "sMEWXllEAD3X"
   },
   "outputs": [],
   "source": [
    "# import libraries\n",
    "from pyspark import SparkContext\n",
    "from pyspark.conf import SparkConf\n",
    "from pyspark.sql import SparkSession\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "from datetime import datetime\n",
    "from pyspark.sql.functions import mean, stddev, col, log\n",
    "from pyspark.sql.functions import to_date, dayofweek, to_timestamp\n",
    "from pyspark.sql import types\n",
    "from pyspark.sql.functions import col, udf\n",
    "from pyspark.sql.types import DateType\n",
    "from pyspark.sql.functions import year, month\n",
    "from pyspark.sql.functions import dayofmonth, weekofyear\n",
    "from pyspark.sql.functions import split, explode\n",
    "from pyspark.sql.functions import coalesce, first, lit\n",
    "from pyspark.ml.feature import Binarizer\n",
    "from pyspark.ml.feature import Bucketizer\n",
    "from pyspark.ml.feature import OneHotEncoder, StringIndexer\n",
    "from pyspark.sql.functions import regexp_extract, col\n",
    "from pyspark.sql.functions import datediff\n",
    "from pyspark.sql.functions import when\n",
    "\n",
    "from pyspark.ml.linalg import Vectors\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.ml.regression import LinearRegression\n",
    "from pyspark.ml.regression import LinearRegressionModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "wnB3qrDkAJNX"
   },
   "outputs": [],
   "source": [
    "sc =SparkContext()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "bxVoyCsJAU1Q"
   },
   "outputs": [],
   "source": [
    "spark = SparkSession(sc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chuẩn bị, chuẩn hóa dữ liệu, xác định input, output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "6uWET97hAOLP"
   },
   "outputs": [],
   "source": [
    "# Use Spark to read in the Ecommerce Customers csv file.\n",
    "data = spark.read.csv(\"flights.csv\", inferSchema=True,header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uVGsiQy3YM42",
    "outputId": "4359bd91-66a3-431c-e78a-bdb53bfefbbf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- mon: integer (nullable = true)\n",
      " |-- dom: integer (nullable = true)\n",
      " |-- dow: integer (nullable = true)\n",
      " |-- carrier: string (nullable = true)\n",
      " |-- flight: integer (nullable = true)\n",
      " |-- org: string (nullable = true)\n",
      " |-- mile: integer (nullable = true)\n",
      " |-- depart: double (nullable = true)\n",
      " |-- duration: integer (nullable = true)\n",
      " |-- delay: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Print the Schema of the DataFrame\n",
    "data.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xTVUD4NLAxM_",
    "outputId": "d008bcae-06aa-48ac-edfb-48ae6f83d5e2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 10)\n"
     ]
    }
   ],
   "source": [
    "print((data.count(), len(data.columns)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9iKmmwibARm3",
    "outputId": "541fda34-37cb-41ff-e46a-9b30e70e50fa"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(mon=11, dom=20, dow=6, carrier='US', flight=19, org='JFK', mile=2153, depart=9.48, duration=351, delay='NA')]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Khi in bằng head thì định dạng hiển thị là row (khác với head ở pandas dataframe)\n",
    "data.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---+---+-------+------+---+----+------+--------+-----+\n",
      "|mon|dom|dow|carrier|flight|org|mile|depart|duration|delay|\n",
      "+---+---+---+-------+------+---+----+------+--------+-----+\n",
      "| 11| 20|  6|     US|    19|JFK|2153|  9.48|     351|   NA|\n",
      "|  0| 22|  2|     UA|  1107|ORD| 316| 16.33|      82|   30|\n",
      "|  2| 20|  4|     UA|   226|SFO| 337|  6.17|      82|   -8|\n",
      "+---+---+---+-------+------+---+----+------+--------+-----+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data.show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nRCdVCcMYX7V",
    "outputId": "fe72fab0-442d-49c0-8114-9bbc93fb120b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11\n",
      "20\n",
      "6\n",
      "US\n",
      "19\n",
      "JFK\n",
      "2153\n",
      "9.48\n",
      "351\n",
      "NA\n"
     ]
    }
   ],
   "source": [
    "for item in data.head():\n",
    "    print(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import round"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.withColumn('km', round(data.mile*1.60934,0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.withColumn('label', (data.delay > 0).cast('integer'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---+---+-------+------+---+----+------+--------+-----+------+-----+\n",
      "|mon|dom|dow|carrier|flight|org|mile|depart|duration|delay|    km|label|\n",
      "+---+---+---+-------+------+---+----+------+--------+-----+------+-----+\n",
      "| 11| 20|  6|     US|    19|JFK|2153|  9.48|     351|   NA|3465.0| NULL|\n",
      "|  0| 22|  2|     UA|  1107|ORD| 316| 16.33|      82|   30| 509.0|    1|\n",
      "|  2| 20|  4|     UA|   226|SFO| 337|  6.17|      82|   -8| 542.0|    0|\n",
      "+---+---+---+-------+------+---+----+------+--------+-----+------+-----+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data.show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import StringIndexer, OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create Indexer\n",
    "indexer = StringIndexer(inputCol='carrier', outputCol='carrier_inx')\n",
    "indexer_model = indexer.fit(data)\n",
    "data_indexed = indexer_model.transform(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Repeat the process for orther categorical feature\n",
    "data_indexed =  StringIndexer(inputCol='org', \n",
    "                              outputCol='org_inx').fit(data_indexed).transform(data_indexed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create encoder\n",
    "data_indexed = OneHotEncoder(inputCol='carrier_inx', \n",
    "                             outputCol='carrier_vec',\n",
    "                            dropLast=True).fit(data_indexed).transform(data_indexed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_indexed = OneHotEncoder(inputCol='org_inx', \n",
    "                             outputCol='org_vec',\n",
    "                            dropLast=True).fit(data_indexed).transform(data_indexed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---+---+-------+------+---+----+------+--------+-----+------+-----+-----------+-------+-------------+-------------+\n",
      "|mon|dom|dow|carrier|flight|org|mile|depart|duration|delay|    km|label|carrier_inx|org_inx|  carrier_vec|      org_vec|\n",
      "+---+---+---+-------+------+---+----+------+--------+-----+------+-----+-----------+-------+-------------+-------------+\n",
      "| 11| 20|  6|     US|    19|JFK|2153|  9.48|     351|   NA|3465.0| NULL|        6.0|    2.0|(8,[6],[1.0])|(7,[2],[1.0])|\n",
      "|  0| 22|  2|     UA|  1107|ORD| 316| 16.33|      82|   30| 509.0|    1|        0.0|    0.0|(8,[0],[1.0])|(7,[0],[1.0])|\n",
      "|  2| 20|  4|     UA|   226|SFO| 337|  6.17|      82|   -8| 542.0|    0|        0.0|    1.0|(8,[0],[1.0])|(7,[1],[1.0])|\n",
      "+---+---+---+-------+------+---+----+------+--------+-----+------+-----+-----------+-------+-------------+-------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data_indexed.show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['mon',\n",
       " 'dom',\n",
       " 'dow',\n",
       " 'carrier',\n",
       " 'flight',\n",
       " 'org',\n",
       " 'mile',\n",
       " 'depart',\n",
       " 'duration',\n",
       " 'delay',\n",
       " 'km',\n",
       " 'label',\n",
       " 'carrier_inx',\n",
       " 'org_inx',\n",
       " 'carrier_vec',\n",
       " 'org_vec']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_indexed.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.linalg import Vectors\n",
    "from pyspark.ml.feature import VectorAssembler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "assembler = VectorAssembler(\n",
    "    inputCols=['mon', 'dom', 'dow','carrier_vec', 'org_vec','km','depart','duration'],\n",
    "    outputCol='features'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_pre = assembler.transform(data_indexed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------------------------------------------------------+\n",
      "|features                                                            |\n",
      "+--------------------------------------------------------------------+\n",
      "|(21,[0,1,2,9,13,18,19,20],[11.0,20.0,6.0,1.0,1.0,3465.0,9.48,351.0])|\n",
      "|(21,[1,2,3,11,18,19,20],[22.0,2.0,1.0,1.0,509.0,16.33,82.0])        |\n",
      "+--------------------------------------------------------------------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data_pre.select('features').show(2, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---+---+-------+------+---+----+------+--------+-----+------+-----+-----------+-------+-------------+-------------+--------------------+\n",
      "|mon|dom|dow|carrier|flight|org|mile|depart|duration|delay|    km|label|carrier_inx|org_inx|  carrier_vec|      org_vec|            features|\n",
      "+---+---+---+-------+------+---+----+------+--------+-----+------+-----+-----------+-------+-------------+-------------+--------------------+\n",
      "| 11| 20|  6|     US|    19|JFK|2153|  9.48|     351|   NA|3465.0| NULL|        6.0|    2.0|(8,[6],[1.0])|(7,[2],[1.0])|(21,[0,1,2,9,13,1...|\n",
      "|  0| 22|  2|     UA|  1107|ORD| 316| 16.33|      82|   30| 509.0|    1|        0.0|    0.0|(8,[0],[1.0])|(7,[0],[1.0])|(21,[1,2,3,11,18,...|\n",
      "+---+---+---+-------+------+---+----+------+--------+-----+------+-----+-----------+-------+-------------+-------------+--------------------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data_pre.show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_data = data_pre.select('features','label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50000"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_data.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "47022"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_data = final_data.na.drop()\n",
    "final_data.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------------------------------------------------------+-----+\n",
      "|features                                                            |label|\n",
      "+--------------------------------------------------------------------+-----+\n",
      "|(21,[0,1,2,9,13,18,19,20],[11.0,20.0,6.0,1.0,1.0,3465.0,9.48,351.0])|NULL |\n",
      "|(21,[0,1,2,4,11,18,19,20],[4.0,2.0,5.0,1.0,1.0,415.0,8.92,65.0])    |NULL |\n",
      "|(21,[1,2,3,11,18,19,20],[8.0,2.0,1.0,1.0,538.0,11.08,85.0])         |NULL |\n",
      "+--------------------------------------------------------------------+-----+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "new_data = data_pre.select('features','label').filter(data_pre.label.isNull())\n",
    "new_data.show(3,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2978"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_data.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, test_data = final_data.randomSplit([0.8,0.2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------------+\n",
      "|summary|             label|\n",
      "+-------+------------------+\n",
      "|  count|             37606|\n",
      "|   mean|0.6377971600276552|\n",
      "| stddev|0.4806434081583298|\n",
      "|    min|                 0|\n",
      "|    max|                 1|\n",
      "+-------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_data.describe().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------------------+\n",
      "|summary|              label|\n",
      "+-------+-------------------+\n",
      "|  count|               9416|\n",
      "|   mean| 0.6363636363636364|\n",
      "| stddev|0.48107123901325205|\n",
      "|    min|                  0|\n",
      "|    max|                  1|\n",
      "+-------+-------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_data.describe().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "logistic = LogisticRegression(featuresCol='features',\n",
    "                         labelCol='label',\n",
    "                         predictionCol='prediction')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "logisticModel = logistic.fit(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+----------+-----+\n",
      "|label|prediction|count|\n",
      "+-----+----------+-----+\n",
      "|    1|       0.0|  556|\n",
      "|    0|       0.0|  697|\n",
      "|    1|       1.0| 5383|\n",
      "|    0|       1.0| 2704|\n",
      "+-----+----------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_model = logisticModel.transform(test_data)\n",
    "test_model.groupBy('label', 'prediction').count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator,  BinaryClassificationEvaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "multi_evaluator = MulticlassClassificationEvaluator()\n",
    "acc_ = multi_evaluator.evaluate(test_model,\n",
    "                               {multi_evaluator.metricName: 'accuracy'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6509635974304069"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "binary_evaluator = BinaryClassificationEvaluator()\n",
    "auc = binary_evaluator.evaluate(test_model,\n",
    "                               {multi_evaluator.metricName: 'areaUnderROC'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.642383441693481"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "logisticModel.save('logisticModel_Flights_50k')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import LogisticRegressionModel\n",
    "logisticModel2 = LogisticRegressionModel.load('logisticModel_Flights_50k')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "unlabeled_data = new_data.select('features')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = logisticModel2.transform(unlabeled_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------------------------------------------------------+----------------------------------------+----------+\n",
      "|features                                                            |probability                             |prediction|\n",
      "+--------------------------------------------------------------------+----------------------------------------+----------+\n",
      "|(21,[0,1,2,9,13,18,19,20],[11.0,20.0,6.0,1.0,1.0,3465.0,9.48,351.0])|[0.606156751478692,0.39384324852130803] |0.0       |\n",
      "|(21,[0,1,2,4,11,18,19,20],[4.0,2.0,5.0,1.0,1.0,415.0,8.92,65.0])    |[0.35470708890989233,0.6452929110901077]|1.0       |\n",
      "|(21,[1,2,3,11,18,19,20],[8.0,2.0,1.0,1.0,538.0,11.08,85.0])         |[0.3143064747227623,0.6856935252772377] |1.0       |\n",
      "|(21,[0,1,3,11,18,19,20],[5.0,8.0,1.0,1.0,378.0,14.48,79.0])         |[0.3429578499304015,0.6570421500695984] |1.0       |\n",
      "|(21,[0,1,2,9,14,18,19,20],[1.0,13.0,3.0,1.0,1.0,344.0,20.0,82.0])   |[0.30768130574146285,0.6923186942585371]|1.0       |\n",
      "+--------------------------------------------------------------------+----------------------------------------+----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictions[['features','probability','prediction']].show(5,False)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
